{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"No_Data_Aug_Mix_Satellite_Google_Maps_Net_Approach_4.ipynb","provenance":[],"authorship_tag":"ABX9TyPRjKoJlfOA1TpI9AUofXLV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JIvPoS93voFM","colab_type":"code","colab":{}},"source":["import argparse\n","import yaml\n","import time\n","import datetime\n","import cv2\n","import torch\n","from torch.autograd import Variable\n","import numpy as np\n","from astropy.visualization import make_lupton_rgb\n","import random\n","import numpy as np\n","from scipy.ndimage import zoom\n","from __future__ import print_function, division\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from scipy import ndimage, misc\n","import warnings\n","import torch.optim as optim\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_absolute_error\n","import sys\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8hcfrKu2GTv","colab_type":"code","colab":{}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXFx0EWf2I07","colab_type":"code","colab":{}},"source":["!cp -r \"/content/drive/My Drive/Colab/Mosquito_Berkeley/satellite\" ./satellite"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixPYoxmQE2Vv","colab_type":"code","outputId":"8f171c4d-d655-4750-ac96-fe8de91eff33","executionInfo":{"status":"ok","timestamp":1586826049239,"user_tz":420,"elapsed":5251,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["!ls satellite/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["38.820636,-77.01538.png  38.898014,-76.97927.png  38.938009,-76.98513.png\n","38.831034,-77.00539.png  38.906416,-76.94851.png  38.939464,-77.05280.png\n","38.864641,-76.98592.png  38.906416,-76.98451.png  38.945614,-77.01564.png\n","38.8731,-76.97281.png\t 38.907205,-77.05396.png  38.952145,-77.07169.png\n","38.874409,-76.95854.png  38.907725,-77.04406.png  38.954471,-77.06362.png\n","38.874658,-76.98730.png  38.913193,-76.99032.png  38.95682,-77.05096.png\n","38.875372,-77.03315.png  38.914004,-77.05731.png  38.956854,-77.05108.png\n","38.884384,-76.93195.png  38.914656,-77.09722.png  38.971088,-77.02990.png\n","38.887646,-77.04767.png  38.920896,-76.96704.png  38.972853,-77.05300.png\n","38.887771,-77.04232.png  38.921453,-77.01448.png  38.972854,-77.05297.png\n","38.888979,-77.00092.png  38.927132,-77.04890.png  38.980315,-77.05194.png\n","38.890913,-77.01556.png  38.931573,-77.04472.png  38.985287,-77.03816.png\n","38.891675,-77.01952.png  38.937768,-77.09681.png  satellite\n","38.891721,-77.02219.png  38.938009,-76.95813.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aJeDZfVhCyKE","colab_type":"code","outputId":"ca295909-e30e-410b-9b99-41a2d0365351","executionInfo":{"status":"ok","timestamp":1586826050818,"user_tz":420,"elapsed":3342,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Apr 14 01:00:49 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bt_0TJWPrB7R","colab_type":"code","colab":{}},"source":["categorical_columns = ['TRAPTYPE', 'ATTRACTANTSUSED', 'SETTIMEOFDAY', 'COLLECTTIMEOFDAY', 'GENUS', 'SPECIES', 'TRAPID','TRAPSITE']\n","numerical_columns = ['LATITUDE', 'LONGITUDE', 'TRAPSET', 'YEAR','TRAPCOLLECT', 'DIFF_DAYS']\n","\n","weather_columns = ['sunriseTime', 'sunsetTime', 'moonPhase', \n","                     'precipIntensity', 'precipIntensityMax', 'precipProbability', 'temperatureHigh', 'temperatureHighTime',\n","                     'temperatureLow', 'temperatureLowTime', 'apparentTemperatureHigh', 'apparentTemperatureHighTime',\n","                     'apparentTemperatureLow', 'apparentTemperatureLowTime', 'dewPoint', 'humidity', 'pressure', 'windSpeed', 'windGust', \n","                     'windGustTime', 'windBearing', 'cloudCover', 'uvIndex', 'uvIndexTime','visibility', 'temperatureMin',\n","                     'temperatureMinTime', 'temperatureMax', 'temperatureMaxTime', 'apparentTemperatureMin','apparentTemperatureMinTime', 'apparentTemperatureMax',\n","                     'apparentTemperatureMaxTime','time']\n","\n","for item in weather_columns:\n","    numerical_columns.append(item + str(14))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdFZ9N7yL5_z","colab_type":"code","outputId":"a5911128-1b84-4a0a-da54-0fd1bdce653a","executionInfo":{"status":"ok","timestamp":1586826054407,"user_tz":420,"elapsed":1601,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["sentinel_frame = pd.read_csv('/content/drive/My Drive/Colab/Mosquito_Berkeley/Approach2/original_mosquito_weather_semi_clean.csv')\n","sentinel_frame[\"TRAPSET\"]= pd.to_datetime(sentinel_frame[\"TRAPSET\"])\n","sentinel_frame[\"TRAPCOLLECT\"]= pd.to_datetime(sentinel_frame[\"TRAPCOLLECT\"])\n","sentinel_frame[\"DIFF_DAYS\"] = (sentinel_frame[\"TRAPCOLLECT\"] - sentinel_frame[\"TRAPSET\"]).dt.days\n","sentinel_frame[\"TRAPSET\"]= sentinel_frame[\"TRAPSET\"].dt.week\n","sentinel_frame[\"TRAPCOLLECT\"]= sentinel_frame[\"TRAPCOLLECT\"].dt.week\n","sentinel_frame[\"LATITUDE2\"]= sentinel_frame[\"LATITUDE\"]\n","sentinel_frame[\"LONGITUDE2\"]= sentinel_frame[\"LONGITUDE\"]\n","\n","for category in categorical_columns:\n","    sentinel_frame[category] = sentinel_frame[category].astype('category')\n","\n","categorical_column_sizes = [len(sentinel_frame[column].cat.categories) for column in categorical_columns]\n","categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n","\n","for col in numerical_columns:\n","    sentinel_frame[col] = (sentinel_frame[col] - sentinel_frame[col].mean()) / (sentinel_frame[col].max() - sentinel_frame[col].min())\n","    \n","def get_categorical_tensor(in_frame, categories):\n","    categorical_data = np.stack([in_frame[col].cat.codes.values for col in categories], 1)\n","    categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n","    return categorical_data\n","\n","def get_numerical_tensor(in_frame, numerical_columns):\n","    numerical_data = np.stack([in_frame[col].values for col in numerical_columns], 1)\n","    numerical_data = torch.tensor(numerical_data, dtype=torch.float)\n","    return numerical_data\n","\n","count = 0\n","for i in sentinel_frame.columns:\n","    print(count, i)\n","    count+= 1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 Unnamed: 0\n","1 X\n","2 Y\n","3 OBJECTID\n","4 TRAPTYPE\n","5 ATTRACTANTSUSED\n","6 TRAPID\n","7 LATITUDE\n","8 LONGITUDE\n","9 ADDRESS\n","10 TOWN\n","11 STATE\n","12 COUNTY\n","13 TRAPSITE\n","14 TRAPSET\n","15 SETTIMEOFDAY\n","16 TRAPCOLLECT\n","17 YEAR\n","18 COLLECTTIMEOFDAY\n","19 GENUS\n","20 SPECIES\n","21 TOTAL\n","22 sunriseTime1\n","23 sunsetTime1\n","24 moonPhase1\n","25 precipIntensity1\n","26 precipIntensityMax1\n","27 precipProbability1\n","28 temperatureHigh1\n","29 temperatureHighTime1\n","30 temperatureLow1\n","31 temperatureLowTime1\n","32 apparentTemperatureHigh1\n","33 apparentTemperatureHighTime1\n","34 apparentTemperatureLow1\n","35 apparentTemperatureLowTime1\n","36 dewPoint1\n","37 humidity1\n","38 pressure1\n","39 windSpeed1\n","40 windGust1\n","41 windGustTime1\n","42 windBearing1\n","43 cloudCover1\n","44 uvIndex1\n","45 uvIndexTime1\n","46 visibility1\n","47 temperatureMin1\n","48 temperatureMinTime1\n","49 temperatureMax1\n","50 temperatureMaxTime1\n","51 apparentTemperatureMin1\n","52 apparentTemperatureMinTime1\n","53 apparentTemperatureMax1\n","54 apparentTemperatureMaxTime1\n","55 icon1\n","56 time1\n","57 precipIntensityMaxTime1\n","58 precipType1\n","59 summary1\n","60 sunriseTime2\n","61 sunsetTime2\n","62 moonPhase2\n","63 precipIntensity2\n","64 precipIntensityMax2\n","65 precipProbability2\n","66 temperatureHigh2\n","67 temperatureHighTime2\n","68 temperatureLow2\n","69 temperatureLowTime2\n","70 apparentTemperatureHigh2\n","71 apparentTemperatureHighTime2\n","72 apparentTemperatureLow2\n","73 apparentTemperatureLowTime2\n","74 dewPoint2\n","75 humidity2\n","76 pressure2\n","77 windSpeed2\n","78 windGust2\n","79 windGustTime2\n","80 windBearing2\n","81 cloudCover2\n","82 uvIndex2\n","83 uvIndexTime2\n","84 visibility2\n","85 temperatureMin2\n","86 temperatureMinTime2\n","87 temperatureMax2\n","88 temperatureMaxTime2\n","89 apparentTemperatureMin2\n","90 apparentTemperatureMinTime2\n","91 apparentTemperatureMax2\n","92 apparentTemperatureMaxTime2\n","93 icon2\n","94 time2\n","95 precipIntensityMaxTime2\n","96 precipType2\n","97 summary2\n","98 sunriseTime3\n","99 sunsetTime3\n","100 moonPhase3\n","101 precipIntensity3\n","102 precipIntensityMax3\n","103 precipProbability3\n","104 temperatureHigh3\n","105 temperatureHighTime3\n","106 temperatureLow3\n","107 temperatureLowTime3\n","108 apparentTemperatureHigh3\n","109 apparentTemperatureHighTime3\n","110 apparentTemperatureLow3\n","111 apparentTemperatureLowTime3\n","112 dewPoint3\n","113 humidity3\n","114 pressure3\n","115 windSpeed3\n","116 windGust3\n","117 windGustTime3\n","118 windBearing3\n","119 cloudCover3\n","120 uvIndex3\n","121 uvIndexTime3\n","122 visibility3\n","123 temperatureMin3\n","124 temperatureMinTime3\n","125 temperatureMax3\n","126 temperatureMaxTime3\n","127 apparentTemperatureMin3\n","128 apparentTemperatureMinTime3\n","129 apparentTemperatureMax3\n","130 apparentTemperatureMaxTime3\n","131 icon3\n","132 time3\n","133 precipIntensityMaxTime3\n","134 precipType3\n","135 summary3\n","136 sunriseTime4\n","137 sunsetTime4\n","138 moonPhase4\n","139 precipIntensity4\n","140 precipIntensityMax4\n","141 precipProbability4\n","142 temperatureHigh4\n","143 temperatureHighTime4\n","144 temperatureLow4\n","145 temperatureLowTime4\n","146 apparentTemperatureHigh4\n","147 apparentTemperatureHighTime4\n","148 apparentTemperatureLow4\n","149 apparentTemperatureLowTime4\n","150 dewPoint4\n","151 humidity4\n","152 pressure4\n","153 windSpeed4\n","154 windGust4\n","155 windGustTime4\n","156 windBearing4\n","157 cloudCover4\n","158 uvIndex4\n","159 uvIndexTime4\n","160 visibility4\n","161 temperatureMin4\n","162 temperatureMinTime4\n","163 temperatureMax4\n","164 temperatureMaxTime4\n","165 apparentTemperatureMin4\n","166 apparentTemperatureMinTime4\n","167 apparentTemperatureMax4\n","168 apparentTemperatureMaxTime4\n","169 icon4\n","170 time4\n","171 precipIntensityMaxTime4\n","172 precipType4\n","173 summary4\n","174 sunriseTime5\n","175 sunsetTime5\n","176 moonPhase5\n","177 precipIntensity5\n","178 precipIntensityMax5\n","179 precipProbability5\n","180 temperatureHigh5\n","181 temperatureHighTime5\n","182 temperatureLow5\n","183 temperatureLowTime5\n","184 apparentTemperatureHigh5\n","185 apparentTemperatureHighTime5\n","186 apparentTemperatureLow5\n","187 apparentTemperatureLowTime5\n","188 dewPoint5\n","189 humidity5\n","190 pressure5\n","191 windSpeed5\n","192 windGust5\n","193 windGustTime5\n","194 windBearing5\n","195 cloudCover5\n","196 uvIndex5\n","197 uvIndexTime5\n","198 visibility5\n","199 temperatureMin5\n","200 temperatureMinTime5\n","201 temperatureMax5\n","202 temperatureMaxTime5\n","203 apparentTemperatureMin5\n","204 apparentTemperatureMinTime5\n","205 apparentTemperatureMax5\n","206 apparentTemperatureMaxTime5\n","207 icon5\n","208 time5\n","209 precipIntensityMaxTime5\n","210 precipType5\n","211 summary5\n","212 sunriseTime6\n","213 sunsetTime6\n","214 moonPhase6\n","215 precipIntensity6\n","216 precipIntensityMax6\n","217 precipProbability6\n","218 temperatureHigh6\n","219 temperatureHighTime6\n","220 temperatureLow6\n","221 temperatureLowTime6\n","222 apparentTemperatureHigh6\n","223 apparentTemperatureHighTime6\n","224 apparentTemperatureLow6\n","225 apparentTemperatureLowTime6\n","226 dewPoint6\n","227 humidity6\n","228 pressure6\n","229 windSpeed6\n","230 windGust6\n","231 windGustTime6\n","232 windBearing6\n","233 cloudCover6\n","234 uvIndex6\n","235 uvIndexTime6\n","236 visibility6\n","237 temperatureMin6\n","238 temperatureMinTime6\n","239 temperatureMax6\n","240 temperatureMaxTime6\n","241 apparentTemperatureMin6\n","242 apparentTemperatureMinTime6\n","243 apparentTemperatureMax6\n","244 apparentTemperatureMaxTime6\n","245 icon6\n","246 time6\n","247 precipIntensityMaxTime6\n","248 precipType6\n","249 summary6\n","250 sunriseTime7\n","251 sunsetTime7\n","252 moonPhase7\n","253 precipIntensity7\n","254 precipIntensityMax7\n","255 precipProbability7\n","256 temperatureHigh7\n","257 temperatureHighTime7\n","258 temperatureLow7\n","259 temperatureLowTime7\n","260 apparentTemperatureHigh7\n","261 apparentTemperatureHighTime7\n","262 apparentTemperatureLow7\n","263 apparentTemperatureLowTime7\n","264 dewPoint7\n","265 humidity7\n","266 pressure7\n","267 windSpeed7\n","268 windGust7\n","269 windGustTime7\n","270 windBearing7\n","271 cloudCover7\n","272 uvIndex7\n","273 uvIndexTime7\n","274 visibility7\n","275 temperatureMin7\n","276 temperatureMinTime7\n","277 temperatureMax7\n","278 temperatureMaxTime7\n","279 apparentTemperatureMin7\n","280 apparentTemperatureMinTime7\n","281 apparentTemperatureMax7\n","282 apparentTemperatureMaxTime7\n","283 icon7\n","284 time7\n","285 precipIntensityMaxTime7\n","286 precipType7\n","287 summary7\n","288 sunriseTime8\n","289 sunsetTime8\n","290 moonPhase8\n","291 precipIntensity8\n","292 precipIntensityMax8\n","293 precipProbability8\n","294 temperatureHigh8\n","295 temperatureHighTime8\n","296 temperatureLow8\n","297 temperatureLowTime8\n","298 apparentTemperatureHigh8\n","299 apparentTemperatureHighTime8\n","300 apparentTemperatureLow8\n","301 apparentTemperatureLowTime8\n","302 dewPoint8\n","303 humidity8\n","304 pressure8\n","305 windSpeed8\n","306 windGust8\n","307 windGustTime8\n","308 windBearing8\n","309 cloudCover8\n","310 uvIndex8\n","311 uvIndexTime8\n","312 visibility8\n","313 temperatureMin8\n","314 temperatureMinTime8\n","315 temperatureMax8\n","316 temperatureMaxTime8\n","317 apparentTemperatureMin8\n","318 apparentTemperatureMinTime8\n","319 apparentTemperatureMax8\n","320 apparentTemperatureMaxTime8\n","321 icon8\n","322 time8\n","323 precipIntensityMaxTime8\n","324 precipType8\n","325 summary8\n","326 sunriseTime9\n","327 sunsetTime9\n","328 moonPhase9\n","329 precipIntensity9\n","330 precipIntensityMax9\n","331 precipProbability9\n","332 temperatureHigh9\n","333 temperatureHighTime9\n","334 temperatureLow9\n","335 temperatureLowTime9\n","336 apparentTemperatureHigh9\n","337 apparentTemperatureHighTime9\n","338 apparentTemperatureLow9\n","339 apparentTemperatureLowTime9\n","340 dewPoint9\n","341 humidity9\n","342 pressure9\n","343 windSpeed9\n","344 windGust9\n","345 windGustTime9\n","346 windBearing9\n","347 cloudCover9\n","348 uvIndex9\n","349 uvIndexTime9\n","350 visibility9\n","351 temperatureMin9\n","352 temperatureMinTime9\n","353 temperatureMax9\n","354 temperatureMaxTime9\n","355 apparentTemperatureMin9\n","356 apparentTemperatureMinTime9\n","357 apparentTemperatureMax9\n","358 apparentTemperatureMaxTime9\n","359 icon9\n","360 time9\n","361 precipIntensityMaxTime9\n","362 precipType9\n","363 summary9\n","364 sunriseTime10\n","365 sunsetTime10\n","366 moonPhase10\n","367 precipIntensity10\n","368 precipIntensityMax10\n","369 precipProbability10\n","370 temperatureHigh10\n","371 temperatureHighTime10\n","372 temperatureLow10\n","373 temperatureLowTime10\n","374 apparentTemperatureHigh10\n","375 apparentTemperatureHighTime10\n","376 apparentTemperatureLow10\n","377 apparentTemperatureLowTime10\n","378 dewPoint10\n","379 humidity10\n","380 pressure10\n","381 windSpeed10\n","382 windGust10\n","383 windGustTime10\n","384 windBearing10\n","385 cloudCover10\n","386 uvIndex10\n","387 uvIndexTime10\n","388 visibility10\n","389 temperatureMin10\n","390 temperatureMinTime10\n","391 temperatureMax10\n","392 temperatureMaxTime10\n","393 apparentTemperatureMin10\n","394 apparentTemperatureMinTime10\n","395 apparentTemperatureMax10\n","396 apparentTemperatureMaxTime10\n","397 icon10\n","398 time10\n","399 precipIntensityMaxTime10\n","400 precipType10\n","401 summary10\n","402 sunriseTime11\n","403 sunsetTime11\n","404 moonPhase11\n","405 precipIntensity11\n","406 precipIntensityMax11\n","407 precipProbability11\n","408 temperatureHigh11\n","409 temperatureHighTime11\n","410 temperatureLow11\n","411 temperatureLowTime11\n","412 apparentTemperatureHigh11\n","413 apparentTemperatureHighTime11\n","414 apparentTemperatureLow11\n","415 apparentTemperatureLowTime11\n","416 dewPoint11\n","417 humidity11\n","418 pressure11\n","419 windSpeed11\n","420 windGust11\n","421 windGustTime11\n","422 windBearing11\n","423 cloudCover11\n","424 uvIndex11\n","425 uvIndexTime11\n","426 visibility11\n","427 temperatureMin11\n","428 temperatureMinTime11\n","429 temperatureMax11\n","430 temperatureMaxTime11\n","431 apparentTemperatureMin11\n","432 apparentTemperatureMinTime11\n","433 apparentTemperatureMax11\n","434 apparentTemperatureMaxTime11\n","435 icon11\n","436 time11\n","437 precipIntensityMaxTime11\n","438 precipType11\n","439 summary11\n","440 sunriseTime12\n","441 sunsetTime12\n","442 moonPhase12\n","443 precipIntensity12\n","444 precipIntensityMax12\n","445 precipProbability12\n","446 temperatureHigh12\n","447 temperatureHighTime12\n","448 temperatureLow12\n","449 temperatureLowTime12\n","450 apparentTemperatureHigh12\n","451 apparentTemperatureHighTime12\n","452 apparentTemperatureLow12\n","453 apparentTemperatureLowTime12\n","454 dewPoint12\n","455 humidity12\n","456 pressure12\n","457 windSpeed12\n","458 windGust12\n","459 windGustTime12\n","460 windBearing12\n","461 cloudCover12\n","462 uvIndex12\n","463 uvIndexTime12\n","464 visibility12\n","465 temperatureMin12\n","466 temperatureMinTime12\n","467 temperatureMax12\n","468 temperatureMaxTime12\n","469 apparentTemperatureMin12\n","470 apparentTemperatureMinTime12\n","471 apparentTemperatureMax12\n","472 apparentTemperatureMaxTime12\n","473 icon12\n","474 time12\n","475 precipIntensityMaxTime12\n","476 precipType12\n","477 summary12\n","478 sunriseTime13\n","479 sunsetTime13\n","480 moonPhase13\n","481 precipIntensity13\n","482 precipIntensityMax13\n","483 precipProbability13\n","484 temperatureHigh13\n","485 temperatureHighTime13\n","486 temperatureLow13\n","487 temperatureLowTime13\n","488 apparentTemperatureHigh13\n","489 apparentTemperatureHighTime13\n","490 apparentTemperatureLow13\n","491 apparentTemperatureLowTime13\n","492 dewPoint13\n","493 humidity13\n","494 pressure13\n","495 windSpeed13\n","496 windGust13\n","497 windGustTime13\n","498 windBearing13\n","499 cloudCover13\n","500 uvIndex13\n","501 uvIndexTime13\n","502 visibility13\n","503 temperatureMin13\n","504 temperatureMinTime13\n","505 temperatureMax13\n","506 temperatureMaxTime13\n","507 apparentTemperatureMin13\n","508 apparentTemperatureMinTime13\n","509 apparentTemperatureMax13\n","510 apparentTemperatureMaxTime13\n","511 icon13\n","512 time13\n","513 precipIntensityMaxTime13\n","514 precipType13\n","515 summary13\n","516 sunriseTime14\n","517 sunsetTime14\n","518 moonPhase14\n","519 precipIntensity14\n","520 precipIntensityMax14\n","521 precipProbability14\n","522 temperatureHigh14\n","523 temperatureHighTime14\n","524 temperatureLow14\n","525 temperatureLowTime14\n","526 apparentTemperatureHigh14\n","527 apparentTemperatureHighTime14\n","528 apparentTemperatureLow14\n","529 apparentTemperatureLowTime14\n","530 dewPoint14\n","531 humidity14\n","532 pressure14\n","533 windSpeed14\n","534 windGust14\n","535 windGustTime14\n","536 windBearing14\n","537 cloudCover14\n","538 uvIndex14\n","539 uvIndexTime14\n","540 visibility14\n","541 temperatureMin14\n","542 temperatureMinTime14\n","543 temperatureMax14\n","544 temperatureMaxTime14\n","545 apparentTemperatureMin14\n","546 apparentTemperatureMinTime14\n","547 apparentTemperatureMax14\n","548 apparentTemperatureMaxTime14\n","549 icon14\n","550 time14\n","551 precipIntensityMaxTime14\n","552 precipType14\n","553 summary14\n","554 DIFF_DAYS\n","555 LATITUDE2\n","556 LONGITUDE2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fHNd25zU3JZG","colab_type":"code","colab":{}},"source":["def paddedzoom(img, zoomfactor=0.8):\n","    out  = np.zeros_like(img)\n","    zoomed = cv2.resize(img, None, fx=zoomfactor, fy=zoomfactor)\n","    \n","    h, w, _ = img.shape\n","    zh, zw, _ = zoomed.shape\n","    if zoomfactor<1:    \n","        out[int((h-zh)/2):int(-(h-zh)/2),int((w-zw)/2):int(-(w-zw)/2),:] = zoomed\n","    else:\n","        out = zoomed[int((zh-h)/2):int(-(zh-h)/2), int((zw-w)/2):int(-(zw-w)/2), :]\n","\n","    return out\n","\n","def get_random_crop(image, crop_height, crop_width):\n","\n","    original_shape = image.shape\n","    max_x = image.shape[1] - crop_width\n","    max_y = image.shape[0] - crop_height\n","\n","    x = np.random.randint(0, max_x)\n","    y = np.random.randint(0, max_y)\n","\n","    crop = image[y: y + crop_height, x: x + crop_width]\n","    resized = cv2.resize(crop, (416, 416), interpolation = cv2.INTER_AREA)\n","\n","    return resized\n","\n","def get_affeine(img, rows, cols):\n","    offset1 = ((random.random() * 2 ) - 1) * 40\n","    offset2 = ((random.random() * 2 ) - 1) * 40\n","    M = np.float32([[1,0,offset1],[0,1,offset2]])\n","    dst = cv2.warpAffine(img,M,(cols,rows))\n","\n","    return dst\n","\n","def distort(img, orientation='horizontal', func=np.sin, x_scale=0.05, y_scale=5):\n","    assert orientation[:3] in ['hor', 'ver'], \"dist_orient should be 'horizontal'|'vertical'\"\n","    assert func in [np.sin, np.cos], \"supported functions are np.sin and np.cos\"\n","    assert 0.00 <= x_scale <= 0.1, \"x_scale should be in [0.0, 0.1]\"\n","    assert 0 <= y_scale <= min(img.shape[0], img.shape[1]), \"y_scale should be less then image size\"\n","    img_dist = img.copy()\n","    \n","    def shift(x):\n","        return int(y_scale * func(np.pi * x * x_scale))\n","    \n","    for c in range(3):\n","        for i in range(img.shape[orientation.startswith('ver')]):\n","            if orientation.startswith('ver'):\n","                img_dist[:, i, c] = np.roll(img[:, i, c], shift(i))\n","            else:\n","                img_dist[i, :, c] = np.roll(img[i, :, c], shift(i))\n","            \n","    return img_dist\n","\n","class SentinelDataset(Dataset):\n","\n","    def __init__(self, root_dir, data, transform=None):\n","        self.data = data\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        \n","\n","        filename = str(self.data.iloc[idx, 555])[0:9]+',' + str(self.data.iloc[idx, 556])[0:9] + '.png'\n","        img_name = os.path.join(self.root_dir, filename)\n","        \n","        image = cv2.imread(img_name)\n","        image = cv2.resize(image, (416, 416), interpolation = cv2.INTER_AREA)\n","\n","        # #random flip\n","        # if np.random.rand() > 0.5:\n","        #     image = np.flip(image, axis=1).copy()\n","        \n","        # # if np.random.rand() > 0.5:\n","        # #     image = distort(image, orientation=random.choice(['ver','hor']), x_scale=random.uniform(0.01, 0.03), y_scale=random.randint(2,10))\n","        \n","        # #random rotate\n","        # image = ndimage.rotate(image, random.randint(0,359), axes = [0,1],reshape=False)\n","\n","        # # random zoom\n","        # or_image = image.copy()\n","        # image = paddedzoom(image, 1.0 + (np.random.rand()/2) )\n","        # if image.shape != or_image.shape:\n","        #     image = or_image\n","        \n","        # if np.random.rand() > 0.2:\n","        #     image = get_random_crop(image, 380, 380)\n","        \n","        # if np.random.rand() > 0.5:\n","        #     image = get_affeine(image, 416, 416)\n","\n","        image = torch.from_numpy(image)\n","\n","        current_row = self.data.iloc[[idx]]\n","        target = current_row['TOTAL'].values\n","\n","        category_tensor = get_categorical_tensor(current_row, categorical_columns)\n","        numerical_tensor = get_numerical_tensor(current_row, numerical_columns)\n","\n","        # from matplotlib.pyplot import figure\n","        # from matplotlib import pyplot as PLT\n","\n","\n","        # PLT.imshow(image)\n","        # PLT.show()\n","        # print(numerical_tensor)\n","        # print(target)\n","        # print(idx)\n","        # raise ValueError('A very specific bad thing happened.')\n","\n","        return image,category_tensor ,numerical_tensor, target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iic6t0xBL8yv","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","\n","from collections import defaultdict\n","\n","class Flatten(torch.nn.Module):\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)\n","\n","def add_conv(in_ch, out_ch, ksize, stride):\n","    stage = nn.Sequential()\n","    pad = (ksize - 1) // 2\n","    stage.add_module('conv', nn.Conv2d(in_channels=in_ch,\n","                                       out_channels=out_ch, kernel_size=ksize, stride=stride,\n","                                       padding=pad, bias=False))\n","    stage.add_module('batch_norm', nn.BatchNorm2d(out_ch))\n","    stage.add_module('leaky', nn.LeakyReLU(0.1))\n","    return stage\n","\n","def add_linear(in_ch, in_dm, out_ch, leaky = True):\n","    stage = nn.Sequential()\n","    stage.add_module('linear', nn.Linear(in_features=in_ch*in_dm*in_dm, out_features=out_ch))\n","    stage.add_module('batch_norm',nn.BatchNorm1d(num_features=out_ch))\n","    if leaky :\n","        stage.add_module('LeakyRelu', nn.LeakyReLU())\n","    else:\n","        stage.add_module('relu', nn.ReLU())\n","\n","    return stage\n","\n","\n","class resblock(nn.Module):\n","    def __init__(self, ch, nblocks=1, shortcut=True):\n","\n","        super().__init__()\n","        self.shortcut = shortcut\n","        self.module_list = nn.ModuleList()\n","        for i in range(nblocks):\n","            resblock_one = nn.ModuleList()\n","            resblock_one.append(add_conv(ch, ch//2, 1, 1))\n","            resblock_one.append(add_conv(ch//2, ch, 3, 1))\n","            self.module_list.append(resblock_one)\n","\n","    def forward(self, x):\n","        for module in self.module_list:\n","            h = x\n","            for res in module:\n","                h = res(h)\n","            x = x + h if self.shortcut else h\n","        return x\n","\n","def create_darknet_modules():\n","\n","    # DarkNet53\n","    mlist = nn.ModuleList()\n","    mlist.append(add_conv(in_ch=3, out_ch=32, ksize=3, stride=1))\n","    mlist.append(add_conv(in_ch=32, out_ch=64, ksize=3, stride=2))\n","    mlist.append(resblock(ch=64))\n","    mlist.append(add_conv(in_ch=64, out_ch=128, ksize=3, stride=2))\n","    mlist.append(resblock(ch=128, nblocks=2))\n","    mlist.append(add_conv(in_ch=128, out_ch=256, ksize=3, stride=2))\n","    mlist.append(resblock(ch=256, nblocks=8))\n","    mlist.append(add_conv(in_ch=256, out_ch=512, ksize=3, stride=2))\n","    mlist.append(resblock(ch=512, nblocks=8)) \n","    mlist.append(add_conv(in_ch=512, out_ch=1024, ksize=3, stride=2))\n","    mlist.append(resblock(ch=1024, nblocks=4))\n","\n","    mlist.append(Flatten())\n","    mlist.append(add_linear(in_ch=1024, in_dm=13, out_ch=2048))\n","    mlist.append(add_linear(in_ch=2048, in_dm=1, out_ch=60))\n","    #mlist.append(add_linear(in_ch=1024, in_dm=1, out_ch=1, leaky = False))\n","\n","    return mlist\n","\n","def create_neural_modules(embedding_size, num_numerical_cols, output_size, hidden_size, dropout = 0.3):\n","    all_layers = []\n","    num_categorical_cols = sum((nf for ni, nf in embedding_size))\n","    input_size = num_categorical_cols + num_numerical_cols\n","    all_layers.append(nn.Linear(input_size, hidden_size))\n","    all_layers.append(nn.LeakyReLU())\n","    all_layers.append(nn.Dropout(dropout))\n","\n","    all_layers.append(nn.Linear(hidden_size, hidden_size))\n","    all_layers.append(nn.LeakyReLU())\n","    all_layers.append(nn.Dropout(dropout))\n","\n","    all_layers.append(nn.Linear(hidden_size, hidden_size))\n","    all_layers.append(nn.LeakyReLU())\n","    all_layers.append(nn.Dropout(dropout))\n","\n","    # all_layers.append(nn.Linear(hidden_size, output_size))\n","    # all_layers.append(nn.ReLU())\n","\n","    return nn.Sequential(*all_layers)\n","\n","def create_mix_modules(input_size, output_size, dropout = 0.3):\n","    all_layers = []\n","    all_layers.append(nn.Linear(input_size, input_size))\n","    all_layers.append(nn.LeakyReLU())\n","    all_layers.append(nn.Dropout(dropout))\n","\n","    all_layers.append(nn.Linear(input_size, input_size))\n","    all_layers.append(nn.LeakyReLU())\n","    all_layers.append(nn.Dropout(dropout))\n","\n","    all_layers.append(nn.Linear(input_size, output_size))\n","    all_layers.append(nn.ReLU())\n","    return nn.Sequential(*all_layers)\n","\n","def turn_conv_lstm_autograd(self):\n","\n","    def dfs_off(model):\n","        for name, child in model.named_children():\n","            for param in child.parameters():\n","                param.requires_grad = False\n","            dfs_off(child)\n","\n","    for i, module in enumerate(self.module_list):\n","        if i == 11:\n","          break\n","        dfs_off(module)\n","\n","class Sentinel_net(nn.Module):\n","\n","    def __init__(self, embedding_size, num_numerical_cols, output_size):\n","        super(Sentinel_net, self).__init__()\n","        self.module_list = create_darknet_modules()\n","        turn_conv_lstm_autograd(self)\n","    \n","        self.layers = create_neural_modules(embedding_size, num_numerical_cols, output_size, 65)\n","        self.mix_layers = create_mix_modules(125, 1)\n","        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n","        self.embedding_dropout = nn.Dropout(0.3)\n","\n","    def forward(self, x, x_categorical, x_numerical):\n","        for i, module in enumerate(self.module_list):\n","            x = module(x)\n","\n","        x = x.squeeze(dim=0)\n","\n","        embeddings = []\n","        for i, e in enumerate(self.all_embeddings):\n","            embeddings.append(e(x_categorical[:, i]))\n","        \n","        y = torch.cat(embeddings, 1)\n","\n","        y = self.embedding_dropout(y)\n","        y = torch.cat([y, x_numerical], 1)\n","\n","        y = self.layers(y).squeeze()\n","                  \n","        #print('x ', x.shape,'y ', y.shape)\n","\n","        mixtensor = torch.cat((x, y), 1)\n","        mixtensor = self.mix_layers(mixtensor)\n","        return mixtensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNlFr4hf1ytn","colab_type":"code","colab":{}},"source":["from __future__ import division\n","import torch\n","import numpy as np\n","\n","\n","def parse_conv_block(m, weights, offset, initflag):\n","    \"\"\"\n","    Initialization of conv layers with batchnorm\n","    Args:\n","        m (Sequential): sequence of layers\n","        weights (numpy.ndarray): pretrained weights data\n","        offset (int): current position in the weights file\n","        initflag (bool): if True, the layers are not covered by the weights file. \\\n","            They are initialized using darknet-style initialization.\n","    Returns:\n","        offset (int): current position in the weights file\n","        weights (numpy.ndarray): pretrained weights data\n","    \"\"\"\n","    conv_model = m[0]\n","    bn_model = m[1]\n","    param_length = m[1].bias.numel()\n","\n","    # batchnorm\n","    for pname in ['bias', 'weight', 'running_mean', 'running_var']:\n","        layerparam = getattr(bn_model, pname)\n","\n","        if initflag: # yolo initialization - scale to one, bias to zero\n","            if pname == 'weight':\n","                weights = np.append(weights, np.ones(param_length))\n","            else:\n","                weights = np.append(weights, np.zeros(param_length))\n","\n","        param = torch.from_numpy(weights[offset:offset + param_length]).view_as(layerparam)\n","        layerparam.data.copy_(param)\n","        offset += param_length\n","\n","    param_length = conv_model.weight.numel()\n","\n","    # conv\n","    if initflag: # yolo initialization\n","        n, c, k, _ = conv_model.weight.shape\n","        scale = np.sqrt(2 / (k * k * c))\n","        weights = np.append(weights, scale * np.random.normal(size=param_length))\n","\n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.weight)\n","    conv_model.weight.data.copy_(param)\n","    offset += param_length\n","\n","    return offset, weights\n","\n","def parse_yolo_block(m, weights, offset, initflag):\n","    \"\"\"\n","    YOLO Layer (one conv with bias) Initialization\n","    Args:\n","        m (Sequential): sequence of layers\n","        weights (numpy.ndarray): pretrained weights data\n","        offset (int): current position in the weights file\n","        initflag (bool): if True, the layers are not covered by the weights file. \\\n","            They are initialized using darknet-style initialization.\n","    Returns:\n","        offset (int): current position in the weights file\n","        weights (numpy.ndarray): pretrained weights data\n","    \"\"\"\n","    conv_model = m._modules['conv']\n","    param_length = conv_model.bias.numel()\n","\n","    if initflag: # yolo initialization - bias to zero\n","        weights = np.append(weights, np.zeros(param_length))\n","\n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.bias)\n","    conv_model.bias.data.copy_(param)\n","    offset += param_length\n","\n","    param_length = conv_model.weight.numel()\n","\n","    if initflag: # yolo initialization\n","        n, c, k, _ = conv_model.weight.shape\n","        scale = np.sqrt(2 / (k * k * c))\n","        weights = np.append(weights, scale * np.random.normal(size=param_length))\n"," \n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.weight)\n","    conv_model.weight.data.copy_(param)\n","    offset += param_length\n","\n","    return offset, weights\n","\n","def parse_yolo_weights(model, weights_path):\n","    \"\"\"\n","    Parse YOLO (darknet) pre-trained weights data onto the pytorch model\n","    Args:\n","        model : pytorch model object\n","        weights_path (str): path to the YOLO (darknet) pre-trained weights file\n","    \"\"\"\n","    fp = open(weights_path, \"rb\")\n","\n","    # skip the header\n","    header = np.fromfile(fp, dtype=np.int32, count=5) # not used\n","    # read weights \n","    weights = np.fromfile(fp, dtype=np.float32)\n","    fp.close()\n","\n","    offset = 0 \n","    initflag = False #whole yolo weights : False, darknet weights : True\n","\n","    for m in model.module_list:\n","        if m._get_name() == 'Sequential':\n","            # normal conv block\n","            offset, weights = parse_conv_block(m, weights, offset, initflag)\n","\n","        elif m._get_name() == 'resblock':\n","            # residual block\n","            for modu in m._modules['module_list']:\n","                for blk in modu:\n","                    offset, weights = parse_conv_block(blk, weights, offset, initflag)\n","        else:\n","            break\n","        # elif m._get_name() == 'YOLOLayer':\n","        #     # YOLO Layer (one conv with bias) Initialization\n","        #     offset, weights = parse_yolo_block(m, weights, offset, initflag)\n","\n","        # initflag = (offset >= len(weights)) # the end of the weights file. turn the flag on"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"35eEstHG_TpG","colab_type":"code","colab":{}},"source":["def train_darknet_net(sentinel_dataset_train,sentinel_dataset_test, fold_count):\n","    model = Sentinel_net(categorical_embedding_sizes,len(numerical_columns),1)\n","    parse_yolo_weights(model, \"/content/drive/My Drive/Colab/mosquito/darknet53.conv.74\")\n","    model = model.cuda()\n","    model.train()\n","\n","    criterion = torch.nn.MSELoss(size_average = True) \n","    # criterion = torch.nn.L1Loss()\n","\n","    params_dict = dict(model.named_parameters())\n","    params = []\n","    base_lr = 0.00001\n","\n","    for key, value in params_dict.items():\n","        if value.requires_grad:\n","          print(key)\n","          if 'weight' in key:\n","              params += [{'params':value, 'weight_decay':4e-3}]\n","          else:\n","              params += [{'params':value, 'weight_decay':0.0}]\n","\n","    optimizer = torch.optim.RMSprop(params, lr=base_lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.9, centered=False)\n","\n","    epochs = 200\n","    min_eval = sys.maxsize\n","    current_score = 0\n","\n","    for epoch in range(0,epochs):\n","        loss_sum = 0\n","        \n","        model.train()\n","        for i_batch, sample_batched in enumerate(train_dataset_loader):\n","            image = sample_batched[0].cuda().float()\n","            image = image.permute(0,3,2,1)/255\n","            cat_tensor = sample_batched[1].squeeze().cuda()\n","            num_tensor = sample_batched[2].squeeze().cuda().float()\n","\n","            #print('image shape ', image.shape,'cat_tensor shape ', cat_tensor.shape,'num_tensor shape ', num_tensor.shape)\n","\n","            y_pred = model(image, cat_tensor, num_tensor)\n","            y = sample_batched[3].cuda().float()\n","\n","            loss = criterion(y_pred, y) \n","            loss.backward() \n","            loss_sum += loss.item()\n","            optimizer.step() \n","            optimizer.zero_grad() \n","\n","        model.eval()\n","        print('Train Accuracy epoch {}, loss {} %'.format(epoch, loss_sum))\n","\n","        with torch.no_grad():\n","\n","            if epoch % 10 == 0:\n","                model.eval()\n","                eval_loss_sum = 0 \n","                result_pred = []\n","                result_act = []\n","                with torch.no_grad():\n","                    y2 = None\n","                    y_pred2 = None\n","                    for i_batch2, sample_batched2 in enumerate(test_dataset_loader):\n","\n","                        image2 = sample_batched2[0].cuda().float()\n","                        image2 = image2.permute(0,3,2,1)/255\n","                        cat_tensor2 = sample_batched2[1].squeeze().cuda()\n","                        num_tensor2 = sample_batched2[2].squeeze().cuda().float()\n","                        #print('test shape ', image.shape,'test shape ', cat_tensor.shape,'test shape ', num_tensor.shape)\n","\n","                        y_pred2 = model(image2,cat_tensor2,num_tensor2)\n","                        y2 = sample_batched2[3].cuda().float()\n","                        eval_loss_sum += criterion(y_pred2, y2) \n","                        result_pred += y_pred2.tolist()\n","                        result_act += y2.tolist()\n","                    \n","                    print('')\n","                    print(' Test Accuracy  {} %'.format( eval_loss_sum))\n","\n","\n","                    if eval_loss_sum < min_eval:\n","                        current_score = mean_absolute_error(result_pred, result_act)\n","                        print(\"Score!\" ,current_score )\n","                        min_eval = eval_loss_sum\n","                        print(\"saved!\" ,current_score )\n","                        torch.save({'iter': epoch,\n","                          'model_state_dict': model.state_dict(),\n","                          'optimizer_state_dict': optimizer.state_dict(),\n","                          'best_ac': min_eval,\n","                          },\n","                          os.path.join('/content/drive/My Drive/Colab/Mosquito_Berkeley/Approach4/no_data_aug_best_approach' + str(fold_count) + '.ckpt'))\n","\n","\n","    return current_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXZgxqyXHKPM","colab_type":"code","outputId":"a12d91ea-0f99-40e9-d12f-c43ba351bae7","executionInfo":{"status":"error","timestamp":1586833865463,"user_tz":420,"elapsed":4169360,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["start_time = time.time()\n","\n","scores = []\n","cv = KFold(n_splits=5, random_state=42, shuffle=True)\n","fold_count = 0\n","for train_index, test_index in cv.split(sentinel_frame, None):\n","    print('Fold')\n","    train, test  = sentinel_frame.iloc[train_index], sentinel_frame.iloc[test_index]\n","\n","    sentinel_dataset_train = SentinelDataset(data=train, root_dir='satellite/')\n","    sentinel_dataset_test = SentinelDataset(data=test, root_dir='satellite/')\n","\n","    train_dataset_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset_train,\n","                                                    batch_size=20,\n","                                                    shuffle=False)\n","    \n","    test_dataset_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset_test,\n","                                                    batch_size=20,\n","                                                    shuffle=False)\n","    \n","\n","    current_score = train_darknet_net(sentinel_dataset_train,sentinel_dataset_test, fold_count)\n","    scores.append(current_score)\n","    fold_count += 1\n","print(scores)\n","print( sum(scores) / len(scores) )\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","layers.0.weight\n","layers.0.bias\n","layers.3.weight\n","layers.3.bias\n","layers.6.weight\n","layers.6.bias\n","mix_layers.0.weight\n","mix_layers.0.bias\n","mix_layers.3.weight\n","mix_layers.3.bias\n","mix_layers.6.weight\n","mix_layers.6.bias\n","all_embeddings.0.weight\n","all_embeddings.1.weight\n","all_embeddings.2.weight\n","all_embeddings.3.weight\n","all_embeddings.4.weight\n","all_embeddings.5.weight\n","all_embeddings.6.weight\n","all_embeddings.7.weight\n","Train Accuracy epoch 0, loss 74941.49207401276 %\n","\n"," Test Accuracy  107323.7109375 %\n","Score! 13.778953377847317\n","saved! 13.778953377847317\n","Train Accuracy epoch 1, loss 62912.59356498718 %\n","Train Accuracy epoch 2, loss 55957.05690383911 %\n","Train Accuracy epoch 3, loss 55022.73391342163 %\n","Train Accuracy epoch 4, loss 54298.39026641846 %\n","Train Accuracy epoch 5, loss 52283.69236755371 %\n","Train Accuracy epoch 6, loss 51408.67493057251 %\n","Train Accuracy epoch 7, loss 50408.45458602905 %\n","Train Accuracy epoch 8, loss 48327.33918762207 %\n","Train Accuracy epoch 9, loss 47119.110427856445 %\n","Train Accuracy epoch 10, loss 47454.16249084473 %\n","\n"," Test Accuracy  98663.7734375 %\n","Score! 13.316181992307122\n","saved! 13.316181992307122\n","Train Accuracy epoch 11, loss 44914.18072891235 %\n","Train Accuracy epoch 12, loss 43834.18439865112 %\n","Train Accuracy epoch 13, loss 41667.75328826904 %\n","Train Accuracy epoch 14, loss 41238.87587738037 %\n","Train Accuracy epoch 15, loss 40865.28734588623 %\n","Train Accuracy epoch 16, loss 39222.433097839355 %\n","Train Accuracy epoch 17, loss 39001.05992126465 %\n","Train Accuracy epoch 18, loss 38708.76152038574 %\n","Train Accuracy epoch 19, loss 37289.44855308533 %\n","Train Accuracy epoch 20, loss 36288.15165710449 %\n","\n"," Test Accuracy  101708.875 %\n","Train Accuracy epoch 21, loss 36312.03767204285 %\n","Train Accuracy epoch 22, loss 35345.26596450806 %\n","Train Accuracy epoch 23, loss 35031.557024002075 %\n","Train Accuracy epoch 24, loss 34771.933599472046 %\n","Train Accuracy epoch 25, loss 33685.018350601196 %\n","Train Accuracy epoch 26, loss 34222.09247970581 %\n","Train Accuracy epoch 27, loss 34145.24401092529 %\n","Train Accuracy epoch 28, loss 33842.20142364502 %\n","Train Accuracy epoch 29, loss 30846.697298049927 %\n","Train Accuracy epoch 30, loss 31506.87452507019 %\n","\n"," Test Accuracy  100939.40625 %\n","Train Accuracy epoch 31, loss 32490.95209503174 %\n","Train Accuracy epoch 32, loss 31207.765209197998 %\n","Train Accuracy epoch 33, loss 30958.31402206421 %\n","Train Accuracy epoch 34, loss 29207.610050201416 %\n","Train Accuracy epoch 35, loss 28290.45955657959 %\n","Train Accuracy epoch 36, loss 29166.665912628174 %\n","Train Accuracy epoch 37, loss 30479.029844284058 %\n","Train Accuracy epoch 38, loss 28758.612476348877 %\n","Train Accuracy epoch 39, loss 27855.437101364136 %\n","Train Accuracy epoch 40, loss 29272.00763130188 %\n","\n"," Test Accuracy  100092.6796875 %\n","Train Accuracy epoch 41, loss 27746.291345596313 %\n","Train Accuracy epoch 42, loss 27311.9172706604 %\n","Train Accuracy epoch 43, loss 27833.198678970337 %\n","Train Accuracy epoch 44, loss 27495.67911720276 %\n","Train Accuracy epoch 45, loss 27235.67876815796 %\n","Train Accuracy epoch 46, loss 27115.471124649048 %\n","Train Accuracy epoch 47, loss 26927.76178741455 %\n","Train Accuracy epoch 48, loss 28933.771837234497 %\n","Train Accuracy epoch 49, loss 26084.655792236328 %\n","Train Accuracy epoch 50, loss 23929.60422515869 %\n","\n"," Test Accuracy  98627.9921875 %\n","Score! 12.840222391697727\n","saved! 12.840222391697727\n","Train Accuracy epoch 51, loss 27109.54683494568 %\n","Train Accuracy epoch 52, loss 25429.829984664917 %\n","Train Accuracy epoch 53, loss 26191.068321228027 %\n","Train Accuracy epoch 54, loss 26339.94797897339 %\n","Train Accuracy epoch 55, loss 25378.80636405945 %\n","Train Accuracy epoch 56, loss 26438.681888580322 %\n","Train Accuracy epoch 57, loss 23580.97992706299 %\n","Train Accuracy epoch 58, loss 24063.66527557373 %\n","Train Accuracy epoch 59, loss 24764.734508514404 %\n","Train Accuracy epoch 60, loss 23405.815006256104 %\n","\n"," Test Accuracy  97325.046875 %\n","Score! 13.302837491757524\n","saved! 13.302837491757524\n","Train Accuracy epoch 61, loss 25040.405515670776 %\n","Train Accuracy epoch 62, loss 23686.07131767273 %\n","Train Accuracy epoch 63, loss 25347.88914489746 %\n","Train Accuracy epoch 64, loss 24605.908081054688 %\n","Train Accuracy epoch 65, loss 26991.506771087646 %\n","Train Accuracy epoch 66, loss 24944.86281967163 %\n","Train Accuracy epoch 67, loss 23753.577917099 %\n","Train Accuracy epoch 68, loss 24283.76362133026 %\n","Train Accuracy epoch 69, loss 23076.71818637848 %\n","Train Accuracy epoch 70, loss 23701.835134506226 %\n","\n"," Test Accuracy  96485.7578125 %\n","Score! 13.451166523091587\n","saved! 13.451166523091587\n","Train Accuracy epoch 71, loss 23009.27747154236 %\n","Train Accuracy epoch 72, loss 22782.341749191284 %\n","Train Accuracy epoch 73, loss 23535.197704315186 %\n","Train Accuracy epoch 74, loss 21899.322291374207 %\n","Train Accuracy epoch 75, loss 21077.82941055298 %\n","Train Accuracy epoch 76, loss 23270.438039779663 %\n","Train Accuracy epoch 77, loss 20341.019939422607 %\n","Train Accuracy epoch 78, loss 21358.095853805542 %\n","Train Accuracy epoch 79, loss 22341.916473388672 %\n","Train Accuracy epoch 80, loss 21763.607402801514 %\n","\n"," Test Accuracy  98651.1015625 %\n","Train Accuracy epoch 81, loss 23115.649181365967 %\n","Train Accuracy epoch 82, loss 21802.617120742798 %\n","Train Accuracy epoch 83, loss 22262.141386032104 %\n","Train Accuracy epoch 84, loss 23691.822421073914 %\n","Train Accuracy epoch 85, loss 22786.29043197632 %\n","Train Accuracy epoch 86, loss 21641.410984039307 %\n","Train Accuracy epoch 87, loss 21094.334342956543 %\n","Train Accuracy epoch 88, loss 20815.298047065735 %\n","Train Accuracy epoch 89, loss 24177.906017303467 %\n","Train Accuracy epoch 90, loss 20736.29842185974 %\n","\n"," Test Accuracy  93884.046875 %\n","Score! 12.995937355138638\n","saved! 12.995937355138638\n","Train Accuracy epoch 91, loss 21643.922848701477 %\n","Train Accuracy epoch 92, loss 21417.89736366272 %\n","Train Accuracy epoch 93, loss 19768.53135585785 %\n","Train Accuracy epoch 94, loss 19718.130979537964 %\n","Train Accuracy epoch 95, loss 21753.482348442078 %\n","Train Accuracy epoch 96, loss 20706.005836486816 %\n","Train Accuracy epoch 97, loss 18969.156267166138 %\n","Train Accuracy epoch 98, loss 19214.84139919281 %\n","Train Accuracy epoch 99, loss 19547.463264465332 %\n","Train Accuracy epoch 100, loss 19928.74294090271 %\n","\n"," Test Accuracy  98882.2421875 %\n","Train Accuracy epoch 101, loss 20050.268199920654 %\n","Train Accuracy epoch 102, loss 19234.977851867676 %\n","Train Accuracy epoch 103, loss 18014.591859817505 %\n","Train Accuracy epoch 104, loss 21225.621463775635 %\n","Train Accuracy epoch 105, loss 21819.519834518433 %\n","Train Accuracy epoch 106, loss 18160.531761169434 %\n","Train Accuracy epoch 107, loss 18398.94285106659 %\n","Train Accuracy epoch 108, loss 19549.214715003967 %\n","Train Accuracy epoch 109, loss 19038.090888023376 %\n","Train Accuracy epoch 110, loss 19064.109603881836 %\n","\n"," Test Accuracy  96734.7109375 %\n","Train Accuracy epoch 111, loss 17940.972784996033 %\n","Train Accuracy epoch 112, loss 18309.48526763916 %\n","Train Accuracy epoch 113, loss 19151.046706199646 %\n","Train Accuracy epoch 114, loss 20776.93602848053 %\n","Train Accuracy epoch 115, loss 18680.46927165985 %\n","Train Accuracy epoch 116, loss 17478.135396003723 %\n","Train Accuracy epoch 117, loss 18462.32612323761 %\n","Train Accuracy epoch 118, loss 18220.01304912567 %\n","Train Accuracy epoch 119, loss 18217.738800048828 %\n","Train Accuracy epoch 120, loss 19039.675728797913 %\n","\n"," Test Accuracy  98052.0703125 %\n","Train Accuracy epoch 121, loss 20682.45026397705 %\n","Train Accuracy epoch 122, loss 19745.10982131958 %\n","Train Accuracy epoch 123, loss 16563.024251937866 %\n","Train Accuracy epoch 124, loss 17321.577998161316 %\n","Train Accuracy epoch 125, loss 18351.898614883423 %\n","Train Accuracy epoch 126, loss 18712.593952178955 %\n","Train Accuracy epoch 127, loss 20083.31152534485 %\n","Train Accuracy epoch 128, loss 17169.524124145508 %\n","Train Accuracy epoch 129, loss 16968.006967544556 %\n","Train Accuracy epoch 130, loss 15827.530758857727 %\n","\n"," Test Accuracy  97241.40625 %\n","Train Accuracy epoch 131, loss 16115.924335479736 %\n","Train Accuracy epoch 132, loss 16184.791029930115 %\n","Train Accuracy epoch 133, loss 18736.742904663086 %\n","Train Accuracy epoch 134, loss 16651.20876312256 %\n","Train Accuracy epoch 135, loss 18024.864933013916 %\n","Train Accuracy epoch 136, loss 15956.992631912231 %\n","Train Accuracy epoch 137, loss 16242.053023338318 %\n","Train Accuracy epoch 138, loss 15795.716877937317 %\n","Train Accuracy epoch 139, loss 16686.368408203125 %\n","Train Accuracy epoch 140, loss 17245.0527009964 %\n","\n"," Test Accuracy  94943.515625 %\n","Train Accuracy epoch 141, loss 17941.452239990234 %\n","Train Accuracy epoch 142, loss 17972.29095840454 %\n","Train Accuracy epoch 143, loss 21386.143981933594 %\n","Train Accuracy epoch 144, loss 17391.72162437439 %\n","Train Accuracy epoch 145, loss 14830.827266693115 %\n","Train Accuracy epoch 146, loss 15205.684865951538 %\n","Train Accuracy epoch 147, loss 18402.649780273438 %\n","Train Accuracy epoch 148, loss 16156.820261001587 %\n","Train Accuracy epoch 149, loss 16128.574927330017 %\n","Train Accuracy epoch 150, loss 14862.693186759949 %\n","\n"," Test Accuracy  93018.109375 %\n","Score! 12.772059003659237\n","saved! 12.772059003659237\n","Train Accuracy epoch 151, loss 17001.659240722656 %\n","Train Accuracy epoch 152, loss 14952.754682540894 %\n","Train Accuracy epoch 153, loss 15013.923586845398 %\n","Train Accuracy epoch 154, loss 16125.155913352966 %\n","Train Accuracy epoch 155, loss 16414.46090888977 %\n","Train Accuracy epoch 156, loss 16223.790684700012 %\n","Train Accuracy epoch 157, loss 15520.946845054626 %\n","Train Accuracy epoch 158, loss 15694.616574287415 %\n","Train Accuracy epoch 159, loss 13671.478247642517 %\n","Train Accuracy epoch 160, loss 14729.460670471191 %\n","\n"," Test Accuracy  93900.3515625 %\n","Train Accuracy epoch 161, loss 13536.37105846405 %\n","Train Accuracy epoch 162, loss 13115.993394851685 %\n","Train Accuracy epoch 163, loss 14211.542837142944 %\n","Train Accuracy epoch 164, loss 14801.067196846008 %\n","Train Accuracy epoch 165, loss 15135.707416534424 %\n","Train Accuracy epoch 166, loss 16595.136736869812 %\n","Train Accuracy epoch 167, loss 16424.28874206543 %\n","Train Accuracy epoch 168, loss 15738.50190448761 %\n","Train Accuracy epoch 169, loss 14547.698784828186 %\n","Train Accuracy epoch 170, loss 17652.849703788757 %\n","\n"," Test Accuracy  98845.6328125 %\n","Train Accuracy epoch 171, loss 14838.813080787659 %\n","Train Accuracy epoch 172, loss 13682.711155891418 %\n","Train Accuracy epoch 173, loss 17605.698227882385 %\n","Train Accuracy epoch 174, loss 15280.979206085205 %\n","Train Accuracy epoch 175, loss 19368.553380966187 %\n","Train Accuracy epoch 176, loss 15249.778518676758 %\n","Train Accuracy epoch 177, loss 13813.054781913757 %\n","Train Accuracy epoch 178, loss 16264.050409317017 %\n","Train Accuracy epoch 179, loss 14800.53318977356 %\n","Train Accuracy epoch 180, loss 14891.90406703949 %\n","\n"," Test Accuracy  97058.8046875 %\n","Train Accuracy epoch 181, loss 12805.346614837646 %\n","Train Accuracy epoch 182, loss 13999.813548088074 %\n","Train Accuracy epoch 183, loss 13899.734090328217 %\n","Train Accuracy epoch 184, loss 16211.194398880005 %\n","Train Accuracy epoch 185, loss 15732.297711372375 %\n","Train Accuracy epoch 186, loss 15236.253947257996 %\n","Train Accuracy epoch 187, loss 14517.304213523865 %\n","Train Accuracy epoch 188, loss 14315.17868423462 %\n","Train Accuracy epoch 189, loss 13728.734246253967 %\n","Train Accuracy epoch 190, loss 14788.153060913086 %\n","\n"," Test Accuracy  97273.4375 %\n","Train Accuracy epoch 191, loss 15043.6091299057 %\n","Train Accuracy epoch 192, loss 14366.916352272034 %\n","Train Accuracy epoch 193, loss 12665.018921852112 %\n","Train Accuracy epoch 194, loss 12454.258719444275 %\n","Train Accuracy epoch 195, loss 14092.833228111267 %\n","Train Accuracy epoch 196, loss 13123.144205570221 %\n","Train Accuracy epoch 197, loss 13734.989356994629 %\n","Train Accuracy epoch 198, loss 14256.382875442505 %\n","Train Accuracy epoch 199, loss 14831.449376106262 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","layers.0.weight\n","layers.0.bias\n","layers.3.weight\n","layers.3.bias\n","layers.6.weight\n","layers.6.bias\n","mix_layers.0.weight\n","mix_layers.0.bias\n","mix_layers.3.weight\n","mix_layers.3.bias\n","mix_layers.6.weight\n","mix_layers.6.bias\n","all_embeddings.0.weight\n","all_embeddings.1.weight\n","all_embeddings.2.weight\n","all_embeddings.3.weight\n","all_embeddings.4.weight\n","all_embeddings.5.weight\n","all_embeddings.6.weight\n","all_embeddings.7.weight\n","Train Accuracy epoch 0, loss 96629.68983650208 %\n","\n"," Test Accuracy  15674.4326171875 %\n","Score! 10.569194946465668\n","saved! 10.569194946465668\n","Train Accuracy epoch 1, loss 82803.22333717346 %\n","Train Accuracy epoch 2, loss 75140.55490112305 %\n","Train Accuracy epoch 3, loss 74103.41262054443 %\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-1f22914bf569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mcurrent_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_darknet_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentinel_dataset_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentinel_dataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfold_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-0e93440fa142>\u001b[0m in \u001b[0;36mtrain_darknet_net\u001b[0;34m(sentinel_dataset_train, sentinel_dataset_test, fold_count)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-000d140f667f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# #random flip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"dnVvx6Fof-lR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}