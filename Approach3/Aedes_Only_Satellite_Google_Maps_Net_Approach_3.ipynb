{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aedes_Only_Satellite_Google_Maps_Net_Approach_3.ipynb","provenance":[],"authorship_tag":"ABX9TyMvJNR/rLXgPIOUFwUsJN59"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JIvPoS93voFM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966440136,"user_tz":420,"elapsed":433,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["import argparse\n","import yaml\n","import time\n","import datetime\n","import cv2\n","import torch\n","from torch.autograd import Variable\n","import numpy as np\n","from astropy.visualization import make_lupton_rgb\n","import random\n","import numpy as np\n","from scipy.ndimage import zoom\n","from __future__ import print_function, division\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from scipy import ndimage, misc\n","import warnings\n","import torch.optim as optim\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_absolute_error\n","import sys\n"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8hcfrKu2GTv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592966443717,"user_tz":420,"elapsed":1522,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"outputId":"f7ca4c80-aba9-4a2f-ac50-a4fc8a4876ca"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nXFx0EWf2I07","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966101045,"user_tz":420,"elapsed":1759,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["!cp -r \"/content/drive/My Drive/BerkeleyResults/satellite\" ./satellite"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixPYoxmQE2Vv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1592966447337,"user_tz":420,"elapsed":1460,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"outputId":"0755353c-4195-4189-aed5-242dc2ff3e1f"},"source":["!ls satellite/"],"execution_count":51,"outputs":[{"output_type":"stream","text":["38.820636,-77.01538.png  38.898014,-76.97927.png  38.938009,-76.98513.png\n","38.831034,-77.00539.png  38.906416,-76.94851.png  38.939464,-77.05280.png\n","38.864641,-76.98592.png  38.906416,-76.98451.png  38.945614,-77.01564.png\n","38.8731,-76.97281.png\t 38.907205,-77.05396.png  38.952145,-77.07169.png\n","38.874409,-76.95854.png  38.907725,-77.04406.png  38.954471,-77.06362.png\n","38.874658,-76.98730.png  38.913193,-76.99032.png  38.95682,-77.05096.png\n","38.875372,-77.03315.png  38.914004,-77.05731.png  38.956854,-77.05108.png\n","38.884384,-76.93195.png  38.914656,-77.09722.png  38.971088,-77.02990.png\n","38.887646,-77.04767.png  38.920896,-76.96704.png  38.972853,-77.05300.png\n","38.887771,-77.04232.png  38.921453,-77.01448.png  38.972854,-77.05297.png\n","38.888979,-77.00092.png  38.927132,-77.04890.png  38.980315,-77.05194.png\n","38.890913,-77.01556.png  38.931573,-77.04472.png  38.985287,-77.03816.png\n","38.891675,-77.01952.png  38.937768,-77.09681.png  satellite\n","38.891721,-77.02219.png  38.938009,-76.95813.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aJeDZfVhCyKE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"status":"ok","timestamp":1592966448612,"user_tz":420,"elapsed":2067,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"outputId":"770cbbed-f059-449c-dabe-e8ef9ce25280"},"source":["!nvidia-smi"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Wed Jun 24 02:40:47 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    33W / 250W |  11397MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bt_0TJWPrB7R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966448614,"user_tz":420,"elapsed":986,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["categorical_columns = ['TRAPTYPE', 'ATTRACTANTSUSED', 'SETTIMEOFDAY', 'COLLECTTIMEOFDAY', 'GENUS', 'SPECIES']\n","numerical_columns = ['LATITUDE', 'LONGITUDE', 'TRAPSET', 'YEAR','TRAPCOLLECT','TRAPSET','TRAPCOLLECT']"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdFZ9N7yL5_z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966449918,"user_tz":420,"elapsed":375,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["sentinel_frame = pd.read_csv('/content/drive/My Drive/BerkeleyResults/Approach3/aedes_mosquito_weather_clean_totallastcolumn.csv')\n","sentinel_frame[\"TRAPSET\"]= pd.to_datetime(sentinel_frame[\"TRAPSET\"]).dt.week\n","sentinel_frame[\"TRAPCOLLECT\"]= pd.to_datetime(sentinel_frame[\"TRAPCOLLECT\"]).dt.week\n","\n","for category in categorical_columns:\n","    sentinel_frame[category] = sentinel_frame[category].astype('category')\n","\n","categorical_column_sizes = [len(sentinel_frame[column].cat.categories) for column in categorical_columns]\n","categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n","\n","# for col in numerical_columns:\n","#     sentinel_frame[col] = (sentinel_frame[col] - sentinel_frame[col].mean()) / (sentinel_frame[col].max() - sentinel_frame[col].min())\n"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHNd25zU3JZG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966451766,"user_tz":420,"elapsed":520,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["def paddedzoom(img, zoomfactor=0.8):\n","    out  = np.zeros_like(img)\n","    zoomed = cv2.resize(img, None, fx=zoomfactor, fy=zoomfactor)\n","    \n","    h, w, _ = img.shape\n","    zh, zw, _ = zoomed.shape\n","    if zoomfactor<1:    \n","        out[int((h-zh)/2):int(-(h-zh)/2),int((w-zw)/2):int(-(w-zw)/2),:] = zoomed\n","    else:\n","        out = zoomed[int((zh-h)/2):int(-(zh-h)/2), int((zw-w)/2):int(-(zw-w)/2), :]\n","\n","    return out\n","\n","def get_random_crop(image, crop_height, crop_width):\n","\n","    original_shape = image.shape\n","    max_x = image.shape[1] - crop_width\n","    max_y = image.shape[0] - crop_height\n","\n","    x = np.random.randint(0, max_x)\n","    y = np.random.randint(0, max_y)\n","\n","    crop = image[y: y + crop_height, x: x + crop_width]\n","    resized = cv2.resize(crop, (416, 416), interpolation = cv2.INTER_AREA)\n","\n","    return resized\n","\n","def get_affeine(img, rows, cols):\n","    offset1 = ((random.random() * 2 ) - 1) * 40\n","    offset2 = ((random.random() * 2 ) - 1) * 40\n","    M = np.float32([[1,0,offset1],[0,1,offset2]])\n","    dst = cv2.warpAffine(img,M,(cols,rows))\n","\n","    return dst\n","\n","def distort(img, orientation='horizontal', func=np.sin, x_scale=0.05, y_scale=5):\n","    assert orientation[:3] in ['hor', 'ver'], \"dist_orient should be 'horizontal'|'vertical'\"\n","    assert func in [np.sin, np.cos], \"supported functions are np.sin and np.cos\"\n","    assert 0.00 <= x_scale <= 0.1, \"x_scale should be in [0.0, 0.1]\"\n","    assert 0 <= y_scale <= min(img.shape[0], img.shape[1]), \"y_scale should be less then image size\"\n","    img_dist = img.copy()\n","    \n","    def shift(x):\n","        return int(y_scale * func(np.pi * x * x_scale))\n","    \n","    for c in range(3):\n","        for i in range(img.shape[orientation.startswith('ver')]):\n","            if orientation.startswith('ver'):\n","                img_dist[:, i, c] = np.roll(img[:, i, c], shift(i))\n","            else:\n","                img_dist[i, :, c] = np.roll(img[i, :, c], shift(i))\n","            \n","    return img_dist\n","\n","class SentinelDataset(Dataset):\n","\n","    def __init__(self, root_dir, data, transform=None):\n","        self.data = data\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        \n","\n","        filename = str(self.data.iloc[idx, 6])[0:9]+',' + str(self.data.iloc[idx, 7])[0:9] + '.png'\n","        img_name = os.path.join(self.root_dir, filename)\n","        \n","        image = cv2.imread(img_name)\n","        image = cv2.resize(image, (416, 416), interpolation = cv2.INTER_AREA)\n","\n","        #random flip\n","        if np.random.rand() > 0.5:\n","            image = np.flip(image, axis=1).copy()\n","        \n","        # if np.random.rand() > 0.5:\n","        #     image = distort(image, orientation=random.choice(['ver','hor']), x_scale=random.uniform(0.01, 0.03), y_scale=random.randint(2,10))\n","        \n","        #random rotate\n","        image = ndimage.rotate(image, random.randint(0,359), axes = [0,1],reshape=False)\n","\n","        # random zoom\n","        or_image = image.copy()\n","        image = paddedzoom(image, 1.0 + (np.random.rand()/2) )\n","        if image.shape != or_image.shape:\n","            image = or_image\n","        \n","        if np.random.rand() > 0.2:\n","            image = get_random_crop(image, 380, 380)\n","        \n","        if np.random.rand() > 0.5:\n","            image = get_affeine(image, 416, 416)\n","\n","        target = self.data.iloc[idx, -1]\n","        image = torch.from_numpy(image)\n","\n","\n","        return image, target"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iic6t0xBL8yv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966453271,"user_tz":420,"elapsed":523,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["import torch\n","import torch.nn as nn\n","\n","from collections import defaultdict\n","\n","class Flatten(torch.nn.Module):\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)\n","\n","def add_conv(in_ch, out_ch, ksize, stride):\n","    stage = nn.Sequential()\n","    pad = (ksize - 1) // 2\n","    stage.add_module('conv', nn.Conv2d(in_channels=in_ch,\n","                                       out_channels=out_ch, kernel_size=ksize, stride=stride,\n","                                       padding=pad, bias=False))\n","    stage.add_module('batch_norm', nn.BatchNorm2d(out_ch))\n","    stage.add_module('leaky', nn.LeakyReLU(0.1))\n","    return stage\n","\n","def add_linear(in_ch, in_dm, out_ch, leaky = True):\n","    stage = nn.Sequential()\n","    stage.add_module('linear', nn.Linear(in_features=in_ch*in_dm*in_dm, out_features=out_ch))\n","    stage.add_module('batch_norm',nn.BatchNorm1d(num_features=out_ch))\n","    if leaky :\n","        stage.add_module('sigmoid', nn.Sigmoid())\n","    else:\n","        stage.add_module('relu', nn.ReLU())\n","\n","    return stage\n","\n","\n","class resblock(nn.Module):\n","    def __init__(self, ch, nblocks=1, shortcut=True):\n","\n","        super().__init__()\n","        self.shortcut = shortcut\n","        self.module_list = nn.ModuleList()\n","        for i in range(nblocks):\n","            resblock_one = nn.ModuleList()\n","            resblock_one.append(add_conv(ch, ch//2, 1, 1))\n","            resblock_one.append(add_conv(ch//2, ch, 3, 1))\n","            self.module_list.append(resblock_one)\n","\n","    def forward(self, x):\n","        for module in self.module_list:\n","            h = x\n","            for res in module:\n","                h = res(h)\n","            x = x + h if self.shortcut else h\n","        return x\n","\n","def create_darknet_modules():\n","\n","    # DarkNet53\n","    mlist = nn.ModuleList()\n","    mlist.append(add_conv(in_ch=3, out_ch=32, ksize=3, stride=1))\n","    mlist.append(add_conv(in_ch=32, out_ch=64, ksize=3, stride=2))\n","    mlist.append(resblock(ch=64))\n","    mlist.append(add_conv(in_ch=64, out_ch=128, ksize=3, stride=2))\n","    mlist.append(resblock(ch=128, nblocks=2))\n","    mlist.append(add_conv(in_ch=128, out_ch=256, ksize=3, stride=2))\n","    mlist.append(resblock(ch=256, nblocks=8))\n","    mlist.append(add_conv(in_ch=256, out_ch=512, ksize=3, stride=2))\n","    mlist.append(resblock(ch=512, nblocks=8)) \n","    mlist.append(add_conv(in_ch=512, out_ch=1024, ksize=3, stride=2))\n","    mlist.append(resblock(ch=1024, nblocks=4))\n","\n","    mlist.append(Flatten())\n","    mlist.append(add_linear(in_ch=1024, in_dm=13, out_ch=1024))\n","    mlist.append(add_linear(in_ch=1024, in_dm=1, out_ch=1024))\n","    mlist.append(add_linear(in_ch=1024, in_dm=1, out_ch=1, leaky = False))\n","\n","    return mlist\n","\n","# def create_neural_modules(embedding_size, num_numerical_cols, output_size, hidden_size, dropout = 0.3):\n","#     all_layers = []\n","#     num_categorical_cols = sum((nf for ni, nf in embedding_size))\n","#     input_size = num_categorical_cols + num_numerical_cols\n","#     all_layers.append(nn.Linear(input_size, hidden_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(hidden_size, hidden_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(hidden_size, hidden_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(hidden_size, output_size))\n","#     all_layers.append(nn.ReLU())\n","\n","#     return nn.Sequential(*all_layers)\n","\n","# def create_mix_modules(input_size, output_size, dropout = 0.3):\n","#     all_layers = []\n","#     all_layers.append(nn.Linear(input_size, input_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(input_size, input_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(input_size, output_size))\n","#     all_layers.append(nn.ReLU())\n","#     return nn.Sequential(*all_layers)\n","\n","def turn_conv_lstm_autograd(self):\n","\n","    def dfs_off(model):\n","        for name, child in model.named_children():\n","            for param in child.parameters():\n","                param.requires_grad = False\n","            dfs_off(child)\n","\n","    for i, module in enumerate(self.module_list):\n","        if i == 11:\n","          break\n","        dfs_off(module)\n","\n","class Sentinel_net(nn.Module):\n","\n","    def __init__(self, embedding_size, num_numerical_cols, output_size):\n","        super(Sentinel_net, self).__init__()\n","        self.module_list = create_darknet_modules()\n","        turn_conv_lstm_autograd(self)\n","    \n","        #self.layers = create_neural_modules(embedding_size, num_numerical_cols, output_size, 65)\n","        #self.mix_layers = create_mix_modules(130, 1)\n","        #self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n","        #self.embedding_dropout = nn.Dropout(0.3)\n","\n","    def forward(self, x, x_categorical, x_numerical):\n","        for i, module in enumerate(self.module_list):\n","            x = module(x)\n","\n","        x = x.squeeze(dim=0)\n","        # embeddings = []\n","        # for i, e in enumerate(self.all_embeddings):\n","        #     embeddings.append(e(x_categorical[:, i]))\n","        \n","\n","        # y = torch.cat(embeddings, 1)\n","\n","        # y = self.embedding_dropout(y)\n","        # y = torch.cat([y, x_numerical], 1)\n","        # y = self.layers(y).squeeze()\n","        # mixtensor = torch.cat((x, y), 0)\n","        # mixtensor = self.mix_layers(mixtensor)\n","        return x"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNlFr4hf1ytn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966454147,"user_tz":420,"elapsed":440,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["from __future__ import division\n","import torch\n","import numpy as np\n","\n","\n","def parse_conv_block(m, weights, offset, initflag):\n","    \"\"\"\n","    Initialization of conv layers with batchnorm\n","    Args:\n","        m (Sequential): sequence of layers\n","        weights (numpy.ndarray): pretrained weights data\n","        offset (int): current position in the weights file\n","        initflag (bool): if True, the layers are not covered by the weights file. \\\n","            They are initialized using darknet-style initialization.\n","    Returns:\n","        offset (int): current position in the weights file\n","        weights (numpy.ndarray): pretrained weights data\n","    \"\"\"\n","    conv_model = m[0]\n","    bn_model = m[1]\n","    param_length = m[1].bias.numel()\n","\n","    # batchnorm\n","    for pname in ['bias', 'weight', 'running_mean', 'running_var']:\n","        layerparam = getattr(bn_model, pname)\n","\n","        if initflag: # yolo initialization - scale to one, bias to zero\n","            if pname == 'weight':\n","                weights = np.append(weights, np.ones(param_length))\n","            else:\n","                weights = np.append(weights, np.zeros(param_length))\n","\n","        param = torch.from_numpy(weights[offset:offset + param_length]).view_as(layerparam)\n","        layerparam.data.copy_(param)\n","        offset += param_length\n","\n","    param_length = conv_model.weight.numel()\n","\n","    # conv\n","    if initflag: # yolo initialization\n","        n, c, k, _ = conv_model.weight.shape\n","        scale = np.sqrt(2 / (k * k * c))\n","        weights = np.append(weights, scale * np.random.normal(size=param_length))\n","\n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.weight)\n","    conv_model.weight.data.copy_(param)\n","    offset += param_length\n","\n","    return offset, weights\n","\n","def parse_yolo_block(m, weights, offset, initflag):\n","    \"\"\"\n","    YOLO Layer (one conv with bias) Initialization\n","    Args:\n","        m (Sequential): sequence of layers\n","        weights (numpy.ndarray): pretrained weights data\n","        offset (int): current position in the weights file\n","        initflag (bool): if True, the layers are not covered by the weights file. \\\n","            They are initialized using darknet-style initialization.\n","    Returns:\n","        offset (int): current position in the weights file\n","        weights (numpy.ndarray): pretrained weights data\n","    \"\"\"\n","    conv_model = m._modules['conv']\n","    param_length = conv_model.bias.numel()\n","\n","    if initflag: # yolo initialization - bias to zero\n","        weights = np.append(weights, np.zeros(param_length))\n","\n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.bias)\n","    conv_model.bias.data.copy_(param)\n","    offset += param_length\n","\n","    param_length = conv_model.weight.numel()\n","\n","    if initflag: # yolo initialization\n","        n, c, k, _ = conv_model.weight.shape\n","        scale = np.sqrt(2 / (k * k * c))\n","        weights = np.append(weights, scale * np.random.normal(size=param_length))\n"," \n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.weight)\n","    conv_model.weight.data.copy_(param)\n","    offset += param_length\n","\n","    return offset, weights\n","\n","def parse_yolo_weights(model, weights_path):\n","    \"\"\"\n","    Parse YOLO (darknet) pre-trained weights data onto the pytorch model\n","    Args:\n","        model : pytorch model object\n","        weights_path (str): path to the YOLO (darknet) pre-trained weights file\n","    \"\"\"\n","    fp = open(weights_path, \"rb\")\n","\n","    # skip the header\n","    header = np.fromfile(fp, dtype=np.int32, count=5) # not used\n","    # read weights \n","    weights = np.fromfile(fp, dtype=np.float32)\n","    fp.close()\n","\n","    offset = 0 \n","    initflag = False #whole yolo weights : False, darknet weights : True\n","\n","    for m in model.module_list:\n","        if m._get_name() == 'Sequential':\n","            # normal conv block\n","            offset, weights = parse_conv_block(m, weights, offset, initflag)\n","\n","        elif m._get_name() == 'resblock':\n","            # residual block\n","            for modu in m._modules['module_list']:\n","                for blk in modu:\n","                    offset, weights = parse_conv_block(blk, weights, offset, initflag)\n","        else:\n","            break\n","        # elif m._get_name() == 'YOLOLayer':\n","        #     # YOLO Layer (one conv with bias) Initialization\n","        #     offset, weights = parse_yolo_block(m, weights, offset, initflag)\n","\n","        # initflag = (offset >= len(weights)) # the end of the weights file. turn the flag on"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"35eEstHG_TpG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592966633833,"user_tz":420,"elapsed":392,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":["def train_darknet_net(sentinel_dataset_train,sentinel_dataset_test):\n","    model = Sentinel_net(categorical_embedding_sizes,len(numerical_columns),1)\n","    parse_yolo_weights(model, \"/content/drive/My Drive/Colab/mosquito/darknet53.conv.74\")\n","    model = model.cuda()\n","    model.train()\n","\n","    criterion = torch.nn.MSELoss(size_average = True) \n","\n","    params_dict = dict(model.named_parameters())\n","    params = []\n","    base_lr = 0.001\n","\n","    for key, value in params_dict.items():\n","        if value.requires_grad:\n","          print(key)\n","          if 'weight' in key:\n","              params += [{'params':value, 'weight_decay':4e-3}]\n","          else:\n","              params += [{'params':value, 'weight_decay':0.0}]\n","\n","    optimizer = torch.optim.RMSprop(params, lr=base_lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.9, centered=False)\n","\n","    epochs = 100\n","    min_eval = sys.maxsize\n","    current_score = 0\n","\n","    for epoch in range(0,epochs):\n","        loss_sum = 0\n","        \n","        model.train()\n","        for i_batch, sample_batched in enumerate(train_dataset_loader):\n","            image = sample_batched[0].cuda().float()\n","            image = image.permute(0,3,2,1)/255\n","            y_pred = model(image, None, None).squeeze()\n","            y = sample_batched[1].cuda().float()\n","\n","            loss = criterion(y_pred, y) \n","            loss.backward() \n","            loss_sum += loss.item()\n","            optimizer.step() \n","            optimizer.zero_grad() \n","\n","        model.eval()\n","        print('Train Accuracy epoch {}, loss {} %'.format(epoch, loss_sum))\n","\n","        with torch.no_grad():\n","\n","            if epoch % 10 == 0:\n","                model.eval()\n","                eval_loss_sum = 0 \n","                result_pred = []\n","                result_act = []\n","                with torch.no_grad():\n","                    y2 = None\n","                    y_pred2 = None\n","                    for i_batch2, sample_batched2 in enumerate(test_dataset_loader):\n","\n","                        image2 = sample_batched2[0].cuda().float()\n","                        image2 = image2.permute(0,3,2,1)/255\n","                        y_pred2 = model(image2,None,None).squeeze()\n","                        y2 = sample_batched2[1].cuda().float()\n","                        eval_loss_sum += criterion(y_pred2, y2) \n","                        result_pred += y_pred2.tolist()\n","                        result_act += y2.tolist()\n","                    \n","                    print('')\n","                    print(' Test Accuracy  {} %'.format( eval_loss_sum))\n","\n","\n","                    if eval_loss_sum < min_eval:\n","                        current_score = mean_absolute_error(result_pred, result_act)\n","                        print(\"Score!\" ,current_score )\n","                        min_eval = eval_loss_sum\n","                        print(\"saved!\" ,current_score )\n","                        torch.save({'iter': epoch,\n","                          'model_state_dict': model.state_dict(),\n","                          'optimizer_state_dict': optimizer.state_dict(),\n","                          'best_ac': min_eval,\n","                          },\n","                          os.path.join('/content/drive/My Drive/BerkeleyResults/Approach3/aedes_best_approach' + str(fold_count) + '.ckpt'))\n","\n","\n","    return current_score"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXZgxqyXHKPM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592995500284,"user_tz":420,"elapsed":28865665,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"outputId":"9a0295c5-0f03-4649-b47b-e97d11fbd208"},"source":["scores = []\n","cv = KFold(n_splits=5, random_state=42, shuffle=True)\n","fold_count = 0\n","for train_index, test_index in cv.split(sentinel_frame, None):\n","    print('Fold')\n","    train, test  = sentinel_frame.iloc[train_index], sentinel_frame.iloc[test_index]\n","\n","    sentinel_dataset_train = SentinelDataset(data=train, root_dir='satellite/')\n","    sentinel_dataset_test = SentinelDataset(data=test, root_dir='satellite/')\n","\n","    train_dataset_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset_train,\n","                                                    batch_size=20,\n","                                                    shuffle=False)\n","    \n","    test_dataset_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset_test,\n","                                                    batch_size=20,\n","                                                    shuffle=False)\n","    \n","\n","    current_score = train_darknet_net(sentinel_dataset_train,sentinel_dataset_test)\n","    scores.append(current_score)\n","    fold_count += 1\n","print(scores)\n","print( sum(scores) / len(scores) )\n"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 3950.0142374038696 %\n","\n"," Test Accuracy  2284.71142578125 %\n","Score! 7.269027273576049\n","saved! 7.269027273576049\n","Train Accuracy epoch 1, loss 3732.9573497772217 %\n","Train Accuracy epoch 2, loss 3528.7748160362244 %\n","Train Accuracy epoch 3, loss 3268.588327884674 %\n","Train Accuracy epoch 4, loss 3258.626567840576 %\n","Train Accuracy epoch 5, loss 3251.3534903526306 %\n","Train Accuracy epoch 6, loss 3073.1120524406433 %\n","Train Accuracy epoch 7, loss 2974.204798221588 %\n","Train Accuracy epoch 8, loss 2996.887432575226 %\n","Train Accuracy epoch 9, loss 2871.7290573120117 %\n","Train Accuracy epoch 10, loss 2849.4464073181152 %\n","\n"," Test Accuracy  1929.4866943359375 %\n","Score! 6.241379289416706\n","saved! 6.241379289416706\n","Train Accuracy epoch 11, loss 2812.600522994995 %\n","Train Accuracy epoch 12, loss 2684.2964124679565 %\n","Train Accuracy epoch 13, loss 2694.260928630829 %\n","Train Accuracy epoch 14, loss 2697.7739729881287 %\n","Train Accuracy epoch 15, loss 2636.690962791443 %\n","Train Accuracy epoch 16, loss 2587.365562438965 %\n","Train Accuracy epoch 17, loss 2652.5007343292236 %\n","Train Accuracy epoch 18, loss 2566.4178714752197 %\n","Train Accuracy epoch 19, loss 2578.1819829940796 %\n","Train Accuracy epoch 20, loss 2472.510465145111 %\n","\n"," Test Accuracy  1887.2420654296875 %\n","Score! 6.236756951268762\n","saved! 6.236756951268762\n","Train Accuracy epoch 21, loss 2447.4544534683228 %\n","Train Accuracy epoch 22, loss 2491.3624691963196 %\n","Train Accuracy epoch 23, loss 2391.871840953827 %\n","Train Accuracy epoch 24, loss 2374.0680022239685 %\n","Train Accuracy epoch 25, loss 2387.64679145813 %\n","Train Accuracy epoch 26, loss 2363.8965072631836 %\n","Train Accuracy epoch 27, loss 2376.998025894165 %\n","Train Accuracy epoch 28, loss 2341.5139508247375 %\n","Train Accuracy epoch 29, loss 2338.397901535034 %\n","Train Accuracy epoch 30, loss 2336.1010456085205 %\n","\n"," Test Accuracy  1823.753662109375 %\n","Score! 5.553194664506352\n","saved! 5.553194664506352\n","Train Accuracy epoch 31, loss 2361.1735277175903 %\n","Train Accuracy epoch 32, loss 2341.6489448547363 %\n","Train Accuracy epoch 33, loss 2354.834189414978 %\n","Train Accuracy epoch 34, loss 2322.4278984069824 %\n","Train Accuracy epoch 35, loss 2385.703100204468 %\n","Train Accuracy epoch 36, loss 2379.75141620636 %\n","Train Accuracy epoch 37, loss 2361.3480434417725 %\n","Train Accuracy epoch 38, loss 2373.73375415802 %\n","Train Accuracy epoch 39, loss 2303.646396636963 %\n","Train Accuracy epoch 40, loss 2349.5248432159424 %\n","\n"," Test Accuracy  1804.4622802734375 %\n","Score! 5.746958941571853\n","saved! 5.746958941571853\n","Train Accuracy epoch 41, loss 2376.2914485931396 %\n","Train Accuracy epoch 42, loss 2350.167356491089 %\n","Train Accuracy epoch 43, loss 2374.8086500167847 %\n","Train Accuracy epoch 44, loss 2346.964705467224 %\n","Train Accuracy epoch 45, loss 2387.3227891921997 %\n","Train Accuracy epoch 46, loss 2373.8935346603394 %\n","Train Accuracy epoch 47, loss 2336.532042503357 %\n","Train Accuracy epoch 48, loss 2339.0915660858154 %\n","Train Accuracy epoch 49, loss 2337.1748447418213 %\n","Train Accuracy epoch 50, loss 2361.200222969055 %\n","\n"," Test Accuracy  1744.172119140625 %\n","Score! 5.801055400511798\n","saved! 5.801055400511798\n","Train Accuracy epoch 51, loss 2345.541271209717 %\n","Train Accuracy epoch 52, loss 2346.054997444153 %\n","Train Accuracy epoch 53, loss 2344.1729459762573 %\n","Train Accuracy epoch 54, loss 2320.7177953720093 %\n","Train Accuracy epoch 55, loss 2326.4368591308594 %\n","Train Accuracy epoch 56, loss 2358.3994636535645 %\n","Train Accuracy epoch 57, loss 2323.767547607422 %\n","Train Accuracy epoch 58, loss 2332.7526597976685 %\n","Train Accuracy epoch 59, loss 2362.3945207595825 %\n","Train Accuracy epoch 60, loss 2362.107409477234 %\n","\n"," Test Accuracy  1739.497802734375 %\n","Score! 5.864378595352173\n","saved! 5.864378595352173\n","Train Accuracy epoch 61, loss 2302.1207571029663 %\n","Train Accuracy epoch 62, loss 2342.0819692611694 %\n","Train Accuracy epoch 63, loss 2357.5536794662476 %\n","Train Accuracy epoch 64, loss 2301.231360435486 %\n","Train Accuracy epoch 65, loss 2371.2322664260864 %\n","Train Accuracy epoch 66, loss 2369.291220664978 %\n","Train Accuracy epoch 67, loss 2346.3354988098145 %\n","Train Accuracy epoch 68, loss 2425.514959335327 %\n","Train Accuracy epoch 69, loss 2337.7910079956055 %\n","Train Accuracy epoch 70, loss 2343.6561517715454 %\n","\n"," Test Accuracy  1792.0784912109375 %\n","Train Accuracy epoch 71, loss 2397.2491903305054 %\n","Train Accuracy epoch 72, loss 2310.6810569763184 %\n","Train Accuracy epoch 73, loss 2329.198175430298 %\n","Train Accuracy epoch 74, loss 2307.35249042511 %\n","Train Accuracy epoch 75, loss 2338.5258598327637 %\n","Train Accuracy epoch 76, loss 2306.7495679855347 %\n","Train Accuracy epoch 77, loss 2396.927558898926 %\n","Train Accuracy epoch 78, loss 2385.1443452835083 %\n","Train Accuracy epoch 79, loss 2339.968029975891 %\n","Train Accuracy epoch 80, loss 2304.065098762512 %\n","\n"," Test Accuracy  1720.0740966796875 %\n","Score! 6.055748614142923\n","saved! 6.055748614142923\n","Train Accuracy epoch 81, loss 2320.6637678146362 %\n","Train Accuracy epoch 82, loss 2336.8156003952026 %\n","Train Accuracy epoch 83, loss 2403.097668647766 %\n","Train Accuracy epoch 84, loss 2331.6556968688965 %\n","Train Accuracy epoch 85, loss 2361.717381477356 %\n","Train Accuracy epoch 86, loss 2348.2412672042847 %\n","Train Accuracy epoch 87, loss 2399.3257751464844 %\n","Train Accuracy epoch 88, loss 2383.801163673401 %\n","Train Accuracy epoch 89, loss 2301.854923248291 %\n","Train Accuracy epoch 90, loss 2318.905468940735 %\n","\n"," Test Accuracy  1755.6746826171875 %\n","Train Accuracy epoch 91, loss 2450.9568767547607 %\n","Train Accuracy epoch 92, loss 2343.3473863601685 %\n","Train Accuracy epoch 93, loss 2336.6881732940674 %\n","Train Accuracy epoch 94, loss 2347.1845169067383 %\n","Train Accuracy epoch 95, loss 2341.118453979492 %\n","Train Accuracy epoch 96, loss 2370.2762479782104 %\n","Train Accuracy epoch 97, loss 2313.3950805664062 %\n","Train Accuracy epoch 98, loss 2390.9632997512817 %\n","Train Accuracy epoch 99, loss 2368.1912689208984 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 5614.537855148315 %\n","\n"," Test Accuracy  587.4412841796875 %\n","Score! 5.244847524363329\n","saved! 5.244847524363329\n","Train Accuracy epoch 1, loss 5348.2537841796875 %\n","Train Accuracy epoch 2, loss 5212.554197311401 %\n","Train Accuracy epoch 3, loss 4919.641392230988 %\n","Train Accuracy epoch 4, loss 4906.253083229065 %\n","Train Accuracy epoch 5, loss 4659.246745586395 %\n","Train Accuracy epoch 6, loss 4723.713824748993 %\n","Train Accuracy epoch 7, loss 4535.493068695068 %\n","Train Accuracy epoch 8, loss 4457.957503795624 %\n","Train Accuracy epoch 9, loss 4359.862648963928 %\n","Train Accuracy epoch 10, loss 4384.053709983826 %\n","\n"," Test Accuracy  444.338623046875 %\n","Score! 4.432030598764472\n","saved! 4.432030598764472\n","Train Accuracy epoch 11, loss 4393.463809967041 %\n","Train Accuracy epoch 12, loss 4141.661988258362 %\n","Train Accuracy epoch 13, loss 4297.626443386078 %\n","Train Accuracy epoch 14, loss 4150.062812805176 %\n","Train Accuracy epoch 15, loss 4031.402271270752 %\n","Train Accuracy epoch 16, loss 3995.477523803711 %\n","Train Accuracy epoch 17, loss 4041.6820430755615 %\n","Train Accuracy epoch 18, loss 3965.276689529419 %\n","Train Accuracy epoch 19, loss 3935.761058807373 %\n","Train Accuracy epoch 20, loss 3763.5667781829834 %\n","\n"," Test Accuracy  387.63555908203125 %\n","Score! 4.008173294628368\n","saved! 4.008173294628368\n","Train Accuracy epoch 21, loss 3846.2110147476196 %\n","Train Accuracy epoch 22, loss 3779.3475799560547 %\n","Train Accuracy epoch 23, loss 3706.4441242218018 %\n","Train Accuracy epoch 24, loss 3820.3645238876343 %\n","Train Accuracy epoch 25, loss 3772.156002998352 %\n","Train Accuracy epoch 26, loss 3699.218403816223 %\n","Train Accuracy epoch 27, loss 3734.151699066162 %\n","Train Accuracy epoch 28, loss 3652.5800924301147 %\n","Train Accuracy epoch 29, loss 3726.8168897628784 %\n","Train Accuracy epoch 30, loss 3685.3309631347656 %\n","\n"," Test Accuracy  376.62432861328125 %\n","Score! 4.391768175012925\n","saved! 4.391768175012925\n","Train Accuracy epoch 31, loss 3701.0375366210938 %\n","Train Accuracy epoch 32, loss 3715.66579914093 %\n","Train Accuracy epoch 33, loss 3607.6291513442993 %\n","Train Accuracy epoch 34, loss 3629.7488803863525 %\n","Train Accuracy epoch 35, loss 3694.3527030944824 %\n","Train Accuracy epoch 36, loss 3777.1401834487915 %\n","Train Accuracy epoch 37, loss 3642.4014644622803 %\n","Train Accuracy epoch 38, loss 3545.735673904419 %\n","Train Accuracy epoch 39, loss 3663.2045879364014 %\n","Train Accuracy epoch 40, loss 3601.181221008301 %\n","\n"," Test Accuracy  426.8334045410156 %\n","Train Accuracy epoch 41, loss 3707.6451416015625 %\n","Train Accuracy epoch 42, loss 3694.5779314041138 %\n","Train Accuracy epoch 43, loss 3527.4596881866455 %\n","Train Accuracy epoch 44, loss 3664.8063049316406 %\n","Train Accuracy epoch 45, loss 3615.5700159072876 %\n","Train Accuracy epoch 46, loss 3639.634136199951 %\n","Train Accuracy epoch 47, loss 3534.09831905365 %\n","Train Accuracy epoch 48, loss 3737.368353843689 %\n","Train Accuracy epoch 49, loss 3636.9335565567017 %\n","Train Accuracy epoch 50, loss 3545.3918228149414 %\n","\n"," Test Accuracy  434.2294006347656 %\n","Train Accuracy epoch 51, loss 3662.437858581543 %\n","Train Accuracy epoch 52, loss 3694.680088996887 %\n","Train Accuracy epoch 53, loss 3639.696375846863 %\n","Train Accuracy epoch 54, loss 3614.286211013794 %\n","Train Accuracy epoch 55, loss 3622.8907613754272 %\n","Train Accuracy epoch 56, loss 3594.6435546875 %\n","Train Accuracy epoch 57, loss 3564.0237188339233 %\n","Train Accuracy epoch 58, loss 3654.4997453689575 %\n","Train Accuracy epoch 59, loss 3620.258243560791 %\n","Train Accuracy epoch 60, loss 3677.3667850494385 %\n","\n"," Test Accuracy  389.5953369140625 %\n","Train Accuracy epoch 61, loss 3632.523218154907 %\n","Train Accuracy epoch 62, loss 3609.73264503479 %\n","Train Accuracy epoch 63, loss 3655.8541374206543 %\n","Train Accuracy epoch 64, loss 3659.1219873428345 %\n","Train Accuracy epoch 65, loss 3583.0423641204834 %\n","Train Accuracy epoch 66, loss 3692.1869144439697 %\n","Train Accuracy epoch 67, loss 3628.446601867676 %\n","Train Accuracy epoch 68, loss 3592.133274078369 %\n","Train Accuracy epoch 69, loss 3523.577314376831 %\n","Train Accuracy epoch 70, loss 3644.914858818054 %\n","\n"," Test Accuracy  446.9364013671875 %\n","Train Accuracy epoch 71, loss 3639.5525970458984 %\n","Train Accuracy epoch 72, loss 3563.219877243042 %\n","Train Accuracy epoch 73, loss 3582.4912366867065 %\n","Train Accuracy epoch 74, loss 3625.050703048706 %\n","Train Accuracy epoch 75, loss 3598.27322101593 %\n","Train Accuracy epoch 76, loss 3635.31636428833 %\n","Train Accuracy epoch 77, loss 3632.071020126343 %\n","Train Accuracy epoch 78, loss 3588.4330139160156 %\n","Train Accuracy epoch 79, loss 3654.816993713379 %\n","Train Accuracy epoch 80, loss 3604.2252292633057 %\n","\n"," Test Accuracy  379.77203369140625 %\n","Train Accuracy epoch 81, loss 3638.4491834640503 %\n","Train Accuracy epoch 82, loss 3662.705677986145 %\n","Train Accuracy epoch 83, loss 3602.0059328079224 %\n","Train Accuracy epoch 84, loss 3551.561086654663 %\n","Train Accuracy epoch 85, loss 3675.1308612823486 %\n","Train Accuracy epoch 86, loss 3613.7696924209595 %\n","Train Accuracy epoch 87, loss 3664.2314987182617 %\n","Train Accuracy epoch 88, loss 3604.2275972366333 %\n","Train Accuracy epoch 89, loss 3674.6786403656006 %\n","Train Accuracy epoch 90, loss 3628.900716781616 %\n","\n"," Test Accuracy  484.7926025390625 %\n","Train Accuracy epoch 91, loss 3692.8338508605957 %\n","Train Accuracy epoch 92, loss 3604.210479736328 %\n","Train Accuracy epoch 93, loss 3638.0296087265015 %\n","Train Accuracy epoch 94, loss 3640.7117710113525 %\n","Train Accuracy epoch 95, loss 3593.1295404434204 %\n","Train Accuracy epoch 96, loss 3581.997812271118 %\n","Train Accuracy epoch 97, loss 3573.5299005508423 %\n","Train Accuracy epoch 98, loss 3592.264980316162 %\n","Train Accuracy epoch 99, loss 3552.708734512329 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 4925.885785102844 %\n","\n"," Test Accuracy  1154.0682373046875 %\n","Score! 6.631958262794583\n","saved! 6.631958262794583\n","Train Accuracy epoch 1, loss 4685.41512298584 %\n","Train Accuracy epoch 2, loss 4570.835826873779 %\n","Train Accuracy epoch 3, loss 4491.25060749054 %\n","Train Accuracy epoch 4, loss 4303.014210700989 %\n","Train Accuracy epoch 5, loss 4299.634254455566 %\n","Train Accuracy epoch 6, loss 4177.043120384216 %\n","Train Accuracy epoch 7, loss 4138.9989376068115 %\n","Train Accuracy epoch 8, loss 4039.6950912475586 %\n","Train Accuracy epoch 9, loss 3994.8601446151733 %\n","Train Accuracy epoch 10, loss 3863.90279006958 %\n","\n"," Test Accuracy  979.9751586914062 %\n","Score! 5.530020207254326\n","saved! 5.530020207254326\n","Train Accuracy epoch 11, loss 3877.0031843185425 %\n","Train Accuracy epoch 12, loss 3849.7505207061768 %\n","Train Accuracy epoch 13, loss 3816.213718891144 %\n","Train Accuracy epoch 14, loss 3725.949321269989 %\n","Train Accuracy epoch 15, loss 3773.804949760437 %\n","Train Accuracy epoch 16, loss 3710.9634375572205 %\n","Train Accuracy epoch 17, loss 3636.4147486686707 %\n","Train Accuracy epoch 18, loss 3743.3971362113953 %\n","Train Accuracy epoch 19, loss 3651.7190351486206 %\n","Train Accuracy epoch 20, loss 3633.264449119568 %\n","\n"," Test Accuracy  838.220703125 %\n","Score! 5.186278363887001\n","saved! 5.186278363887001\n","Train Accuracy epoch 21, loss 3718.861985206604 %\n","Train Accuracy epoch 22, loss 3567.8200941085815 %\n","Train Accuracy epoch 23, loss 3625.75971698761 %\n","Train Accuracy epoch 24, loss 3576.3476905822754 %\n","Train Accuracy epoch 25, loss 3654.588792324066 %\n","Train Accuracy epoch 26, loss 3614.587866783142 %\n","Train Accuracy epoch 27, loss 3520.0074157714844 %\n","Train Accuracy epoch 28, loss 3455.35245513916 %\n","Train Accuracy epoch 29, loss 3426.0341777801514 %\n","Train Accuracy epoch 30, loss 3423.4949593544006 %\n","\n"," Test Accuracy  952.0167236328125 %\n","Train Accuracy epoch 31, loss 3413.902678489685 %\n","Train Accuracy epoch 32, loss 3445.8617877960205 %\n","Train Accuracy epoch 33, loss 3395.326313972473 %\n","Train Accuracy epoch 34, loss 3392.6834535598755 %\n","Train Accuracy epoch 35, loss 3392.1231117248535 %\n","Train Accuracy epoch 36, loss 3380.544129371643 %\n","Train Accuracy epoch 37, loss 3338.43501663208 %\n","Train Accuracy epoch 38, loss 3428.813105583191 %\n","Train Accuracy epoch 39, loss 3338.697235107422 %\n","Train Accuracy epoch 40, loss 3367.961775779724 %\n","\n"," Test Accuracy  804.3245849609375 %\n","Score! 5.455609436596141\n","saved! 5.455609436596141\n","Train Accuracy epoch 41, loss 3328.227975845337 %\n","Train Accuracy epoch 42, loss 3415.0770330429077 %\n","Train Accuracy epoch 43, loss 3370.513876914978 %\n","Train Accuracy epoch 44, loss 3379.247953414917 %\n","Train Accuracy epoch 45, loss 3347.7616243362427 %\n","Train Accuracy epoch 46, loss 3393.403721809387 %\n","Train Accuracy epoch 47, loss 3376.2741889953613 %\n","Train Accuracy epoch 48, loss 3332.415265083313 %\n","Train Accuracy epoch 49, loss 3362.8606147766113 %\n","Train Accuracy epoch 50, loss 3319.31689453125 %\n","\n"," Test Accuracy  860.7108154296875 %\n","Train Accuracy epoch 51, loss 3412.2085313796997 %\n","Train Accuracy epoch 52, loss 3333.314761161804 %\n","Train Accuracy epoch 53, loss 3365.1644382476807 %\n","Train Accuracy epoch 54, loss 3380.148247718811 %\n","Train Accuracy epoch 55, loss 3408.6020250320435 %\n","Train Accuracy epoch 56, loss 3327.4017972946167 %\n","Train Accuracy epoch 57, loss 3348.8057947158813 %\n","Train Accuracy epoch 58, loss 3327.8460178375244 %\n","Train Accuracy epoch 59, loss 3364.5472116470337 %\n","Train Accuracy epoch 60, loss 3350.6632261276245 %\n","\n"," Test Accuracy  807.9506225585938 %\n","Train Accuracy epoch 61, loss 3339.652193069458 %\n","Train Accuracy epoch 62, loss 3408.438509941101 %\n","Train Accuracy epoch 63, loss 3367.3787775039673 %\n","Train Accuracy epoch 64, loss 3372.7293243408203 %\n","Train Accuracy epoch 65, loss 3396.1077213287354 %\n","Train Accuracy epoch 66, loss 3362.31236743927 %\n","Train Accuracy epoch 67, loss 3345.305640220642 %\n","Train Accuracy epoch 68, loss 3310.622663497925 %\n","Train Accuracy epoch 69, loss 3403.231767654419 %\n","Train Accuracy epoch 70, loss 3351.8706274032593 %\n","\n"," Test Accuracy  863.2212524414062 %\n","Train Accuracy epoch 71, loss 3342.803247451782 %\n","Train Accuracy epoch 72, loss 3324.5769262313843 %\n","Train Accuracy epoch 73, loss 3357.5193300247192 %\n","Train Accuracy epoch 74, loss 3360.3119440078735 %\n","Train Accuracy epoch 75, loss 3303.698872566223 %\n","Train Accuracy epoch 76, loss 3342.888303756714 %\n","Train Accuracy epoch 77, loss 3428.169143676758 %\n","Train Accuracy epoch 78, loss 3363.747138977051 %\n","Train Accuracy epoch 79, loss 3356.633108139038 %\n","Train Accuracy epoch 80, loss 3372.817943572998 %\n","\n"," Test Accuracy  789.6751708984375 %\n","Score! 5.583504132663502\n","saved! 5.583504132663502\n","Train Accuracy epoch 81, loss 3388.4216632843018 %\n","Train Accuracy epoch 82, loss 3368.2278909683228 %\n","Train Accuracy epoch 83, loss 3383.294761657715 %\n","Train Accuracy epoch 84, loss 3378.3633995056152 %\n","Train Accuracy epoch 85, loss 3327.9333171844482 %\n","Train Accuracy epoch 86, loss 3325.1769313812256 %\n","Train Accuracy epoch 87, loss 3344.3416452407837 %\n","Train Accuracy epoch 88, loss 3366.845311164856 %\n","Train Accuracy epoch 89, loss 3375.294870376587 %\n","Train Accuracy epoch 90, loss 3362.6386289596558 %\n","\n"," Test Accuracy  829.4025268554688 %\n","Train Accuracy epoch 91, loss 3402.433886528015 %\n","Train Accuracy epoch 92, loss 3398.2177381515503 %\n","Train Accuracy epoch 93, loss 3387.360608100891 %\n","Train Accuracy epoch 94, loss 3408.17223072052 %\n","Train Accuracy epoch 95, loss 3378.527442932129 %\n","Train Accuracy epoch 96, loss 3367.815969467163 %\n","Train Accuracy epoch 97, loss 3379.9451513290405 %\n","Train Accuracy epoch 98, loss 3353.2166357040405 %\n","Train Accuracy epoch 99, loss 3379.5334186553955 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 5426.987242698669 %\n","\n"," Test Accuracy  771.9077758789062 %\n","Score! 5.579625651218436\n","saved! 5.579625651218436\n","Train Accuracy epoch 1, loss 5157.058644294739 %\n","Train Accuracy epoch 2, loss 5011.281346321106 %\n","Train Accuracy epoch 3, loss 4758.5925216674805 %\n","Train Accuracy epoch 4, loss 4665.109502792358 %\n","Train Accuracy epoch 5, loss 4550.391471862793 %\n","Train Accuracy epoch 6, loss 4422.0717878341675 %\n","Train Accuracy epoch 7, loss 4355.838103294373 %\n","Train Accuracy epoch 8, loss 4314.896464347839 %\n","Train Accuracy epoch 9, loss 4318.817030906677 %\n","Train Accuracy epoch 10, loss 4224.4946031570435 %\n","\n"," Test Accuracy  619.8882446289062 %\n","Score! 5.008202502788866\n","saved! 5.008202502788866\n","Train Accuracy epoch 11, loss 4369.730842590332 %\n","Train Accuracy epoch 12, loss 4066.049554824829 %\n","Train Accuracy epoch 13, loss 4116.5639662742615 %\n","Train Accuracy epoch 14, loss 4052.8765149116516 %\n","Train Accuracy epoch 15, loss 4046.143585205078 %\n","Train Accuracy epoch 16, loss 3998.4262137413025 %\n","Train Accuracy epoch 17, loss 3974.9936151504517 %\n","Train Accuracy epoch 18, loss 3997.2619609832764 %\n","Train Accuracy epoch 19, loss 4025.3112392425537 %\n","Train Accuracy epoch 20, loss 3937.1532106399536 %\n","\n"," Test Accuracy  531.4014892578125 %\n","Score! 4.981018743444891\n","saved! 4.981018743444891\n","Train Accuracy epoch 21, loss 3911.1106605529785 %\n","Train Accuracy epoch 22, loss 3904.4923458099365 %\n","Train Accuracy epoch 23, loss 3956.126664161682 %\n","Train Accuracy epoch 24, loss 3869.7980461120605 %\n","Train Accuracy epoch 25, loss 3768.963536262512 %\n","Train Accuracy epoch 26, loss 3895.422357559204 %\n","Train Accuracy epoch 27, loss 3815.9247035980225 %\n","Train Accuracy epoch 28, loss 3879.777413368225 %\n","Train Accuracy epoch 29, loss 3844.9285097122192 %\n","Train Accuracy epoch 30, loss 3797.8828887939453 %\n","\n"," Test Accuracy  501.4354553222656 %\n","Score! 4.833870373052709\n","saved! 4.833870373052709\n","Train Accuracy epoch 31, loss 3706.5168228149414 %\n","Train Accuracy epoch 32, loss 3787.724075317383 %\n","Train Accuracy epoch 33, loss 3729.2323484420776 %\n","Train Accuracy epoch 34, loss 3705.587844848633 %\n","Train Accuracy epoch 35, loss 3531.601083755493 %\n","Train Accuracy epoch 36, loss 3572.966486930847 %\n","Train Accuracy epoch 37, loss 3643.699472427368 %\n","Train Accuracy epoch 38, loss 3654.628246307373 %\n","Train Accuracy epoch 39, loss 3577.6165342330933 %\n","Train Accuracy epoch 40, loss 3539.6021671295166 %\n","\n"," Test Accuracy  441.478271484375 %\n","Score! 4.48149716573603\n","saved! 4.48149716573603\n","Train Accuracy epoch 41, loss 3554.706534385681 %\n","Train Accuracy epoch 42, loss 3608.4730339050293 %\n","Train Accuracy epoch 43, loss 3565.8436937332153 %\n","Train Accuracy epoch 44, loss 3524.4194927215576 %\n","Train Accuracy epoch 45, loss 3464.84663772583 %\n","Train Accuracy epoch 46, loss 3643.0476989746094 %\n","Train Accuracy epoch 47, loss 3535.7354860305786 %\n","Train Accuracy epoch 48, loss 3631.739959716797 %\n","Train Accuracy epoch 49, loss 3555.0436868667603 %\n","Train Accuracy epoch 50, loss 3567.320243835449 %\n","\n"," Test Accuracy  461.5271301269531 %\n","Train Accuracy epoch 51, loss 3551.4399633407593 %\n","Train Accuracy epoch 52, loss 3488.9797801971436 %\n","Train Accuracy epoch 53, loss 3534.3472719192505 %\n","Train Accuracy epoch 54, loss 3568.274984359741 %\n","Train Accuracy epoch 55, loss 3577.731132507324 %\n","Train Accuracy epoch 56, loss 3555.4019441604614 %\n","Train Accuracy epoch 57, loss 3549.0942249298096 %\n","Train Accuracy epoch 58, loss 3564.183338165283 %\n","Train Accuracy epoch 59, loss 3508.598437309265 %\n","Train Accuracy epoch 60, loss 3589.5980405807495 %\n","\n"," Test Accuracy  520.52294921875 %\n","Train Accuracy epoch 61, loss 3591.929250717163 %\n","Train Accuracy epoch 62, loss 3620.604839324951 %\n","Train Accuracy epoch 63, loss 3493.0506534576416 %\n","Train Accuracy epoch 64, loss 3525.3045654296875 %\n","Train Accuracy epoch 65, loss 3575.900552749634 %\n","Train Accuracy epoch 66, loss 3516.9478635787964 %\n","Train Accuracy epoch 67, loss 3483.5103511810303 %\n","Train Accuracy epoch 68, loss 3617.848222732544 %\n","Train Accuracy epoch 69, loss 3572.6251668930054 %\n","Train Accuracy epoch 70, loss 3575.4642162323 %\n","\n"," Test Accuracy  509.93182373046875 %\n","Train Accuracy epoch 71, loss 3608.951759338379 %\n","Train Accuracy epoch 72, loss 3585.326144218445 %\n","Train Accuracy epoch 73, loss 3536.8576078414917 %\n","Train Accuracy epoch 74, loss 3554.0093154907227 %\n","Train Accuracy epoch 75, loss 3535.677745819092 %\n","Train Accuracy epoch 76, loss 3559.6688737869263 %\n","Train Accuracy epoch 77, loss 3544.0973320007324 %\n","Train Accuracy epoch 78, loss 3557.2712078094482 %\n","Train Accuracy epoch 79, loss 3562.834804534912 %\n","Train Accuracy epoch 80, loss 3553.38907623291 %\n","\n"," Test Accuracy  475.0821228027344 %\n","Train Accuracy epoch 81, loss 3581.8697261810303 %\n","Train Accuracy epoch 82, loss 3548.234136581421 %\n","Train Accuracy epoch 83, loss 3526.4211444854736 %\n","Train Accuracy epoch 84, loss 3617.4784259796143 %\n","Train Accuracy epoch 85, loss 3544.944981575012 %\n","Train Accuracy epoch 86, loss 3542.593433380127 %\n","Train Accuracy epoch 87, loss 3551.185338973999 %\n","Train Accuracy epoch 88, loss 3540.520781517029 %\n","Train Accuracy epoch 89, loss 3579.8488235473633 %\n","Train Accuracy epoch 90, loss 3616.4956970214844 %\n","\n"," Test Accuracy  674.7313232421875 %\n","Train Accuracy epoch 91, loss 3567.6017141342163 %\n","Train Accuracy epoch 92, loss 3533.500665664673 %\n","Train Accuracy epoch 93, loss 3501.7183799743652 %\n","Train Accuracy epoch 94, loss 3591.377589225769 %\n","Train Accuracy epoch 95, loss 3678.123025894165 %\n","Train Accuracy epoch 96, loss 3589.9700679779053 %\n","Train Accuracy epoch 97, loss 3515.224789619446 %\n","Train Accuracy epoch 98, loss 3576.397123336792 %\n","Train Accuracy epoch 99, loss 3508.4700508117676 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 4948.4123458862305 %\n","\n"," Test Accuracy  1293.3116455078125 %\n","Score! 7.126318112979917\n","saved! 7.126318112979917\n","Train Accuracy epoch 1, loss 4676.4926404953 %\n","Train Accuracy epoch 2, loss 4505.765641212463 %\n","Train Accuracy epoch 3, loss 4387.497399806976 %\n","Train Accuracy epoch 4, loss 4279.300075531006 %\n","Train Accuracy epoch 5, loss 4182.193735599518 %\n","Train Accuracy epoch 6, loss 4078.8673100471497 %\n","Train Accuracy epoch 7, loss 4059.114914417267 %\n","Train Accuracy epoch 8, loss 3989.717550754547 %\n","Train Accuracy epoch 9, loss 3873.3680386543274 %\n","Train Accuracy epoch 10, loss 3944.826229095459 %\n","\n"," Test Accuracy  1114.4378662109375 %\n","Score! 6.182611346376293\n","saved! 6.182611346376293\n","Train Accuracy epoch 11, loss 3869.002074241638 %\n","Train Accuracy epoch 12, loss 3850.1760697364807 %\n","Train Accuracy epoch 13, loss 3736.2426624298096 %\n","Train Accuracy epoch 14, loss 3703.0215458869934 %\n","Train Accuracy epoch 15, loss 3706.620536804199 %\n","Train Accuracy epoch 16, loss 3659.2199716567993 %\n","Train Accuracy epoch 17, loss 3703.9854278564453 %\n","Train Accuracy epoch 18, loss 3650.8527059555054 %\n","Train Accuracy epoch 19, loss 3563.1840982437134 %\n","Train Accuracy epoch 20, loss 3610.6204166412354 %\n","\n"," Test Accuracy  951.7281494140625 %\n","Score! 5.811597549301736\n","saved! 5.811597549301736\n","Train Accuracy epoch 21, loss 3526.807685852051 %\n","Train Accuracy epoch 22, loss 3516.303282737732 %\n","Train Accuracy epoch 23, loss 3530.8933696746826 %\n","Train Accuracy epoch 24, loss 3492.2896184921265 %\n","Train Accuracy epoch 25, loss 3459.3910551071167 %\n","Train Accuracy epoch 26, loss 3481.4228534698486 %\n","Train Accuracy epoch 27, loss 3379.97256565094 %\n","Train Accuracy epoch 28, loss 3384.3217725753784 %\n","Train Accuracy epoch 29, loss 3376.9143390655518 %\n","Train Accuracy epoch 30, loss 3396.6781673431396 %\n","\n"," Test Accuracy  968.5216674804688 %\n","Train Accuracy epoch 31, loss 3402.2080793380737 %\n","Train Accuracy epoch 32, loss 3378.230812072754 %\n","Train Accuracy epoch 33, loss 3321.9837007522583 %\n","Train Accuracy epoch 34, loss 3306.9672060012817 %\n","Train Accuracy epoch 35, loss 3311.0573167800903 %\n","Train Accuracy epoch 36, loss 3333.6550521850586 %\n","Train Accuracy epoch 37, loss 3288.18416595459 %\n","Train Accuracy epoch 38, loss 3308.733868598938 %\n","Train Accuracy epoch 39, loss 3287.1593837738037 %\n","Train Accuracy epoch 40, loss 3331.6601543426514 %\n","\n"," Test Accuracy  805.850830078125 %\n","Score! 5.622044473535874\n","saved! 5.622044473535874\n","Train Accuracy epoch 41, loss 3307.9229135513306 %\n","Train Accuracy epoch 42, loss 3307.9288654327393 %\n","Train Accuracy epoch 43, loss 3330.769275665283 %\n","Train Accuracy epoch 44, loss 3265.700563430786 %\n","Train Accuracy epoch 45, loss 3282.773539543152 %\n","Train Accuracy epoch 46, loss 3268.262942314148 %\n","Train Accuracy epoch 47, loss 3276.7000007629395 %\n","Train Accuracy epoch 48, loss 3277.4373846054077 %\n","Train Accuracy epoch 49, loss 3284.9329357147217 %\n","Train Accuracy epoch 50, loss 3277.471815109253 %\n","\n"," Test Accuracy  815.1292724609375 %\n","Train Accuracy epoch 51, loss 3320.285919189453 %\n","Train Accuracy epoch 52, loss 3300.5176429748535 %\n","Train Accuracy epoch 53, loss 3237.541513442993 %\n","Train Accuracy epoch 54, loss 3229.047595977783 %\n","Train Accuracy epoch 55, loss 3228.0488414764404 %\n","Train Accuracy epoch 56, loss 3257.109517097473 %\n","Train Accuracy epoch 57, loss 3264.4148454666138 %\n","Train Accuracy epoch 58, loss 3273.038496017456 %\n","Train Accuracy epoch 59, loss 3233.5960206985474 %\n","Train Accuracy epoch 60, loss 3219.501178741455 %\n","\n"," Test Accuracy  830.9896850585938 %\n","Train Accuracy epoch 61, loss 3302.2794885635376 %\n","Train Accuracy epoch 62, loss 3263.9427452087402 %\n","Train Accuracy epoch 63, loss 3205.3268365859985 %\n","Train Accuracy epoch 64, loss 3264.4071044921875 %\n","Train Accuracy epoch 65, loss 3244.2017316818237 %\n","Train Accuracy epoch 66, loss 3229.4068126678467 %\n","Train Accuracy epoch 67, loss 3266.2385568618774 %\n","Train Accuracy epoch 68, loss 3322.6886129379272 %\n","Train Accuracy epoch 69, loss 3253.8938179016113 %\n","Train Accuracy epoch 70, loss 3289.2581930160522 %\n","\n"," Test Accuracy  858.387939453125 %\n","Train Accuracy epoch 71, loss 3299.320056915283 %\n","Train Accuracy epoch 72, loss 3212.8270559310913 %\n","Train Accuracy epoch 73, loss 3232.7216939926147 %\n","Train Accuracy epoch 74, loss 3269.4591722488403 %\n","Train Accuracy epoch 75, loss 3193.746771812439 %\n","Train Accuracy epoch 76, loss 3237.585047721863 %\n","Train Accuracy epoch 77, loss 3270.8655862808228 %\n","Train Accuracy epoch 78, loss 3265.773645401001 %\n","Train Accuracy epoch 79, loss 3257.1354837417603 %\n","Train Accuracy epoch 80, loss 3255.594609260559 %\n","\n"," Test Accuracy  809.4775390625 %\n","Train Accuracy epoch 81, loss 3193.1599349975586 %\n","Train Accuracy epoch 82, loss 3266.633436203003 %\n","Train Accuracy epoch 83, loss 3264.3038568496704 %\n","Train Accuracy epoch 84, loss 3293.198892593384 %\n","Train Accuracy epoch 85, loss 3174.791986465454 %\n","Train Accuracy epoch 86, loss 3286.772656440735 %\n","Train Accuracy epoch 87, loss 3303.0837411880493 %\n","Train Accuracy epoch 88, loss 3266.5556802749634 %\n","Train Accuracy epoch 89, loss 3229.5870323181152 %\n","Train Accuracy epoch 90, loss 3263.6591653823853 %\n","\n"," Test Accuracy  812.4691162109375 %\n","Train Accuracy epoch 91, loss 3266.4088945388794 %\n","Train Accuracy epoch 92, loss 3237.6141414642334 %\n","Train Accuracy epoch 93, loss 3271.5638217926025 %\n","Train Accuracy epoch 94, loss 3188.7434701919556 %\n","Train Accuracy epoch 95, loss 3181.353536605835 %\n","Train Accuracy epoch 96, loss 3224.4521770477295 %\n","Train Accuracy epoch 97, loss 3260.619149208069 %\n","Train Accuracy epoch 98, loss 3255.5524892807007 %\n","Train Accuracy epoch 99, loss 3335.232597351074 %\n","[6.055748614142923, 4.391768175012925, 5.583504132663502, 4.48149716573603, 5.622044473535874]\n","5.226912512218251\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6TlUKrd9LQmN","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1592966116716,"user_tz":420,"elapsed":3759,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}}},"source":[""],"execution_count":null,"outputs":[]}]}