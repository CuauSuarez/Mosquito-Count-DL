{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Only_Satellite_Google_Maps_Net_Approach_3.ipynb","provenance":[],"authorship_tag":"ABX9TyMqqrTb5Q5IBWRZDGWf3Diq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JIvPoS93voFM","colab_type":"code","colab":{}},"source":["import argparse\n","import yaml\n","import time\n","import datetime\n","import cv2\n","import torch\n","from torch.autograd import Variable\n","import numpy as np\n","from astropy.visualization import make_lupton_rgb\n","import random\n","import numpy as np\n","from scipy.ndimage import zoom\n","from __future__ import print_function, division\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from scipy import ndimage, misc\n","import warnings\n","import torch.optim as optim\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_absolute_error\n","import sys\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8hcfrKu2GTv","colab_type":"code","outputId":"bc827e09-959b-4697-dddf-707b8b11fd2e","executionInfo":{"status":"ok","timestamp":1586370336893,"user_tz":420,"elapsed":170337,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nXFx0EWf2I07","colab_type":"code","colab":{}},"source":["!cp -r \"/content/drive/My Drive/Colab/Mosquito_Berkeley/satellite\" ./satellite"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixPYoxmQE2Vv","colab_type":"code","outputId":"5d4d5c1b-1286-48ad-ffe9-43ccd210fee5","executionInfo":{"status":"ok","timestamp":1586370386453,"user_tz":420,"elapsed":40524,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["!ls satellite/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["38.820636,-77.01538.png  38.898014,-76.97927.png  38.938009,-76.98513.png\n","38.831034,-77.00539.png  38.906416,-76.94851.png  38.939464,-77.05280.png\n","38.864641,-76.98592.png  38.906416,-76.98451.png  38.945614,-77.01564.png\n","38.8731,-76.97281.png\t 38.907205,-77.05396.png  38.952145,-77.07169.png\n","38.874409,-76.95854.png  38.907725,-77.04406.png  38.954471,-77.06362.png\n","38.874658,-76.98730.png  38.913193,-76.99032.png  38.95682,-77.05096.png\n","38.875372,-77.03315.png  38.914004,-77.05731.png  38.956854,-77.05108.png\n","38.884384,-76.93195.png  38.914656,-77.09722.png  38.971088,-77.02990.png\n","38.887646,-77.04767.png  38.920896,-76.96704.png  38.972853,-77.05300.png\n","38.887771,-77.04232.png  38.921453,-77.01448.png  38.972854,-77.05297.png\n","38.888979,-77.00092.png  38.927132,-77.04890.png  38.980315,-77.05194.png\n","38.890913,-77.01556.png  38.931573,-77.04472.png  38.985287,-77.03816.png\n","38.891675,-77.01952.png  38.937768,-77.09681.png  satellite\n","38.891721,-77.02219.png  38.938009,-76.95813.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aJeDZfVhCyKE","colab_type":"code","outputId":"8190110d-2159-474d-bf69-32f266684be0","executionInfo":{"status":"ok","timestamp":1586370399149,"user_tz":420,"elapsed":2878,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wed Apr  8 18:26:37 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bt_0TJWPrB7R","colab_type":"code","colab":{}},"source":["categorical_columns = ['TRAPTYPE', 'ATTRACTANTSUSED', 'SETTIMEOFDAY', 'COLLECTTIMEOFDAY', 'GENUS', 'SPECIES']\n","numerical_columns = ['LATITUDE', 'LONGITUDE', 'TRAPSET', 'YEAR','TRAPCOLLECT','TRAPSET','TRAPCOLLECT']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdFZ9N7yL5_z","colab_type":"code","colab":{}},"source":["sentinel_frame = pd.read_csv('/content/drive/My Drive/Colab/Mosquito_Berkeley/original_mosquito.csv')\n","sentinel_frame[\"TRAPSET\"]= pd.to_datetime(sentinel_frame[\"TRAPSET\"]).dt.week\n","sentinel_frame[\"TRAPCOLLECT\"]= pd.to_datetime(sentinel_frame[\"TRAPCOLLECT\"]).dt.week\n","\n","for category in categorical_columns:\n","    sentinel_frame[category] = sentinel_frame[category].astype('category')\n","\n","categorical_column_sizes = [len(sentinel_frame[column].cat.categories) for column in categorical_columns]\n","categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n","\n","# for col in numerical_columns:\n","#     sentinel_frame[col] = (sentinel_frame[col] - sentinel_frame[col].mean()) / (sentinel_frame[col].max() - sentinel_frame[col].min())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fHNd25zU3JZG","colab_type":"code","colab":{}},"source":["def paddedzoom(img, zoomfactor=0.8):\n","    out  = np.zeros_like(img)\n","    zoomed = cv2.resize(img, None, fx=zoomfactor, fy=zoomfactor)\n","    \n","    h, w, _ = img.shape\n","    zh, zw, _ = zoomed.shape\n","    if zoomfactor<1:    \n","        out[int((h-zh)/2):int(-(h-zh)/2),int((w-zw)/2):int(-(w-zw)/2),:] = zoomed\n","    else:\n","        out = zoomed[int((zh-h)/2):int(-(zh-h)/2), int((zw-w)/2):int(-(zw-w)/2), :]\n","\n","    return out\n","\n","def get_random_crop(image, crop_height, crop_width):\n","\n","    original_shape = image.shape\n","    max_x = image.shape[1] - crop_width\n","    max_y = image.shape[0] - crop_height\n","\n","    x = np.random.randint(0, max_x)\n","    y = np.random.randint(0, max_y)\n","\n","    crop = image[y: y + crop_height, x: x + crop_width]\n","    resized = cv2.resize(crop, (416, 416), interpolation = cv2.INTER_AREA)\n","\n","    return resized\n","\n","def get_affeine(img, rows, cols):\n","    offset1 = ((random.random() * 2 ) - 1) * 40\n","    offset2 = ((random.random() * 2 ) - 1) * 40\n","    M = np.float32([[1,0,offset1],[0,1,offset2]])\n","    dst = cv2.warpAffine(img,M,(cols,rows))\n","\n","    return dst\n","\n","def distort(img, orientation='horizontal', func=np.sin, x_scale=0.05, y_scale=5):\n","    assert orientation[:3] in ['hor', 'ver'], \"dist_orient should be 'horizontal'|'vertical'\"\n","    assert func in [np.sin, np.cos], \"supported functions are np.sin and np.cos\"\n","    assert 0.00 <= x_scale <= 0.1, \"x_scale should be in [0.0, 0.1]\"\n","    assert 0 <= y_scale <= min(img.shape[0], img.shape[1]), \"y_scale should be less then image size\"\n","    img_dist = img.copy()\n","    \n","    def shift(x):\n","        return int(y_scale * func(np.pi * x * x_scale))\n","    \n","    for c in range(3):\n","        for i in range(img.shape[orientation.startswith('ver')]):\n","            if orientation.startswith('ver'):\n","                img_dist[:, i, c] = np.roll(img[:, i, c], shift(i))\n","            else:\n","                img_dist[i, :, c] = np.roll(img[i, :, c], shift(i))\n","            \n","    return img_dist\n","\n","class SentinelDataset(Dataset):\n","\n","    def __init__(self, root_dir, data, transform=None):\n","        self.data = data\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        \n","\n","        filename = str(self.data.iloc[idx, 6])[0:9]+',' + str(self.data.iloc[idx, 7])[0:9] + '.png'\n","        img_name = os.path.join(self.root_dir, filename)\n","        \n","        image = cv2.imread(img_name)\n","        image = cv2.resize(image, (416, 416), interpolation = cv2.INTER_AREA)\n","\n","        #random flip\n","        if np.random.rand() > 0.5:\n","            image = np.flip(image, axis=1).copy()\n","        \n","        # if np.random.rand() > 0.5:\n","        #     image = distort(image, orientation=random.choice(['ver','hor']), x_scale=random.uniform(0.01, 0.03), y_scale=random.randint(2,10))\n","        \n","        #random rotate\n","        image = ndimage.rotate(image, random.randint(0,359), axes = [0,1],reshape=False)\n","\n","        # random zoom\n","        or_image = image.copy()\n","        image = paddedzoom(image, 1.0 + (np.random.rand()/2) )\n","        if image.shape != or_image.shape:\n","            image = or_image\n","        \n","        if np.random.rand() > 0.2:\n","            image = get_random_crop(image, 380, 380)\n","        \n","        if np.random.rand() > 0.5:\n","            image = get_affeine(image, 416, 416)\n","\n","        target = self.data.iloc[idx, -1]\n","        image = torch.from_numpy(image)\n","\n","\n","        return image, target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iic6t0xBL8yv","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","\n","from collections import defaultdict\n","\n","class Flatten(torch.nn.Module):\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)\n","\n","def add_conv(in_ch, out_ch, ksize, stride):\n","    stage = nn.Sequential()\n","    pad = (ksize - 1) // 2\n","    stage.add_module('conv', nn.Conv2d(in_channels=in_ch,\n","                                       out_channels=out_ch, kernel_size=ksize, stride=stride,\n","                                       padding=pad, bias=False))\n","    stage.add_module('batch_norm', nn.BatchNorm2d(out_ch))\n","    stage.add_module('leaky', nn.LeakyReLU(0.1))\n","    return stage\n","\n","def add_linear(in_ch, in_dm, out_ch, leaky = True):\n","    stage = nn.Sequential()\n","    stage.add_module('linear', nn.Linear(in_features=in_ch*in_dm*in_dm, out_features=out_ch))\n","    stage.add_module('batch_norm',nn.BatchNorm1d(num_features=out_ch))\n","    if leaky :\n","        stage.add_module('sigmoid', nn.Sigmoid())\n","    else:\n","        stage.add_module('relu', nn.ReLU())\n","\n","    return stage\n","\n","\n","class resblock(nn.Module):\n","    def __init__(self, ch, nblocks=1, shortcut=True):\n","\n","        super().__init__()\n","        self.shortcut = shortcut\n","        self.module_list = nn.ModuleList()\n","        for i in range(nblocks):\n","            resblock_one = nn.ModuleList()\n","            resblock_one.append(add_conv(ch, ch//2, 1, 1))\n","            resblock_one.append(add_conv(ch//2, ch, 3, 1))\n","            self.module_list.append(resblock_one)\n","\n","    def forward(self, x):\n","        for module in self.module_list:\n","            h = x\n","            for res in module:\n","                h = res(h)\n","            x = x + h if self.shortcut else h\n","        return x\n","\n","def create_darknet_modules():\n","\n","    # DarkNet53\n","    mlist = nn.ModuleList()\n","    mlist.append(add_conv(in_ch=3, out_ch=32, ksize=3, stride=1))\n","    mlist.append(add_conv(in_ch=32, out_ch=64, ksize=3, stride=2))\n","    mlist.append(resblock(ch=64))\n","    mlist.append(add_conv(in_ch=64, out_ch=128, ksize=3, stride=2))\n","    mlist.append(resblock(ch=128, nblocks=2))\n","    mlist.append(add_conv(in_ch=128, out_ch=256, ksize=3, stride=2))\n","    mlist.append(resblock(ch=256, nblocks=8))\n","    mlist.append(add_conv(in_ch=256, out_ch=512, ksize=3, stride=2))\n","    mlist.append(resblock(ch=512, nblocks=8)) \n","    mlist.append(add_conv(in_ch=512, out_ch=1024, ksize=3, stride=2))\n","    mlist.append(resblock(ch=1024, nblocks=4))\n","\n","    mlist.append(Flatten())\n","    mlist.append(add_linear(in_ch=1024, in_dm=13, out_ch=1024))\n","    mlist.append(add_linear(in_ch=1024, in_dm=1, out_ch=1024))\n","    mlist.append(add_linear(in_ch=1024, in_dm=1, out_ch=1, leaky = False))\n","\n","    return mlist\n","\n","# def create_neural_modules(embedding_size, num_numerical_cols, output_size, hidden_size, dropout = 0.3):\n","#     all_layers = []\n","#     num_categorical_cols = sum((nf for ni, nf in embedding_size))\n","#     input_size = num_categorical_cols + num_numerical_cols\n","#     all_layers.append(nn.Linear(input_size, hidden_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(hidden_size, hidden_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(hidden_size, hidden_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(hidden_size, output_size))\n","#     all_layers.append(nn.ReLU())\n","\n","#     return nn.Sequential(*all_layers)\n","\n","# def create_mix_modules(input_size, output_size, dropout = 0.3):\n","#     all_layers = []\n","#     all_layers.append(nn.Linear(input_size, input_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(input_size, input_size))\n","#     all_layers.append(nn.Sigmoid())\n","#     all_layers.append(nn.Dropout(dropout))\n","\n","#     all_layers.append(nn.Linear(input_size, output_size))\n","#     all_layers.append(nn.ReLU())\n","#     return nn.Sequential(*all_layers)\n","\n","def turn_conv_lstm_autograd(self):\n","\n","    def dfs_off(model):\n","        for name, child in model.named_children():\n","            for param in child.parameters():\n","                param.requires_grad = False\n","            dfs_off(child)\n","\n","    for i, module in enumerate(self.module_list):\n","        if i == 11:\n","          break\n","        dfs_off(module)\n","\n","class Sentinel_net(nn.Module):\n","\n","    def __init__(self, embedding_size, num_numerical_cols, output_size):\n","        super(Sentinel_net, self).__init__()\n","        self.module_list = create_darknet_modules()\n","        turn_conv_lstm_autograd(self)\n","    \n","        #self.layers = create_neural_modules(embedding_size, num_numerical_cols, output_size, 65)\n","        #self.mix_layers = create_mix_modules(130, 1)\n","        #self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n","        #self.embedding_dropout = nn.Dropout(0.3)\n","\n","    def forward(self, x, x_categorical, x_numerical):\n","        for i, module in enumerate(self.module_list):\n","            x = module(x)\n","\n","        x = x.squeeze(dim=0)\n","        # embeddings = []\n","        # for i, e in enumerate(self.all_embeddings):\n","        #     embeddings.append(e(x_categorical[:, i]))\n","        \n","\n","        # y = torch.cat(embeddings, 1)\n","\n","        # y = self.embedding_dropout(y)\n","        # y = torch.cat([y, x_numerical], 1)\n","        # y = self.layers(y).squeeze()\n","        # mixtensor = torch.cat((x, y), 0)\n","        # mixtensor = self.mix_layers(mixtensor)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNlFr4hf1ytn","colab_type":"code","colab":{}},"source":["from __future__ import division\n","import torch\n","import numpy as np\n","\n","\n","def parse_conv_block(m, weights, offset, initflag):\n","    \"\"\"\n","    Initialization of conv layers with batchnorm\n","    Args:\n","        m (Sequential): sequence of layers\n","        weights (numpy.ndarray): pretrained weights data\n","        offset (int): current position in the weights file\n","        initflag (bool): if True, the layers are not covered by the weights file. \\\n","            They are initialized using darknet-style initialization.\n","    Returns:\n","        offset (int): current position in the weights file\n","        weights (numpy.ndarray): pretrained weights data\n","    \"\"\"\n","    conv_model = m[0]\n","    bn_model = m[1]\n","    param_length = m[1].bias.numel()\n","\n","    # batchnorm\n","    for pname in ['bias', 'weight', 'running_mean', 'running_var']:\n","        layerparam = getattr(bn_model, pname)\n","\n","        if initflag: # yolo initialization - scale to one, bias to zero\n","            if pname == 'weight':\n","                weights = np.append(weights, np.ones(param_length))\n","            else:\n","                weights = np.append(weights, np.zeros(param_length))\n","\n","        param = torch.from_numpy(weights[offset:offset + param_length]).view_as(layerparam)\n","        layerparam.data.copy_(param)\n","        offset += param_length\n","\n","    param_length = conv_model.weight.numel()\n","\n","    # conv\n","    if initflag: # yolo initialization\n","        n, c, k, _ = conv_model.weight.shape\n","        scale = np.sqrt(2 / (k * k * c))\n","        weights = np.append(weights, scale * np.random.normal(size=param_length))\n","\n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.weight)\n","    conv_model.weight.data.copy_(param)\n","    offset += param_length\n","\n","    return offset, weights\n","\n","def parse_yolo_block(m, weights, offset, initflag):\n","    \"\"\"\n","    YOLO Layer (one conv with bias) Initialization\n","    Args:\n","        m (Sequential): sequence of layers\n","        weights (numpy.ndarray): pretrained weights data\n","        offset (int): current position in the weights file\n","        initflag (bool): if True, the layers are not covered by the weights file. \\\n","            They are initialized using darknet-style initialization.\n","    Returns:\n","        offset (int): current position in the weights file\n","        weights (numpy.ndarray): pretrained weights data\n","    \"\"\"\n","    conv_model = m._modules['conv']\n","    param_length = conv_model.bias.numel()\n","\n","    if initflag: # yolo initialization - bias to zero\n","        weights = np.append(weights, np.zeros(param_length))\n","\n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.bias)\n","    conv_model.bias.data.copy_(param)\n","    offset += param_length\n","\n","    param_length = conv_model.weight.numel()\n","\n","    if initflag: # yolo initialization\n","        n, c, k, _ = conv_model.weight.shape\n","        scale = np.sqrt(2 / (k * k * c))\n","        weights = np.append(weights, scale * np.random.normal(size=param_length))\n"," \n","    param = torch.from_numpy(\n","        weights[offset:offset + param_length]).view_as(conv_model.weight)\n","    conv_model.weight.data.copy_(param)\n","    offset += param_length\n","\n","    return offset, weights\n","\n","def parse_yolo_weights(model, weights_path):\n","    \"\"\"\n","    Parse YOLO (darknet) pre-trained weights data onto the pytorch model\n","    Args:\n","        model : pytorch model object\n","        weights_path (str): path to the YOLO (darknet) pre-trained weights file\n","    \"\"\"\n","    fp = open(weights_path, \"rb\")\n","\n","    # skip the header\n","    header = np.fromfile(fp, dtype=np.int32, count=5) # not used\n","    # read weights \n","    weights = np.fromfile(fp, dtype=np.float32)\n","    fp.close()\n","\n","    offset = 0 \n","    initflag = False #whole yolo weights : False, darknet weights : True\n","\n","    for m in model.module_list:\n","        if m._get_name() == 'Sequential':\n","            # normal conv block\n","            offset, weights = parse_conv_block(m, weights, offset, initflag)\n","\n","        elif m._get_name() == 'resblock':\n","            # residual block\n","            for modu in m._modules['module_list']:\n","                for blk in modu:\n","                    offset, weights = parse_conv_block(blk, weights, offset, initflag)\n","        else:\n","            break\n","        # elif m._get_name() == 'YOLOLayer':\n","        #     # YOLO Layer (one conv with bias) Initialization\n","        #     offset, weights = parse_yolo_block(m, weights, offset, initflag)\n","\n","        # initflag = (offset >= len(weights)) # the end of the weights file. turn the flag on"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"35eEstHG_TpG","colab_type":"code","colab":{}},"source":["def train_darknet_net(sentinel_dataset_train,sentinel_dataset_test):\n","    model = Sentinel_net(categorical_embedding_sizes,len(numerical_columns),1)\n","    parse_yolo_weights(model, \"/content/drive/My Drive/Colab/mosquito/darknet53.conv.74\")\n","    model = model.cuda()\n","    model.train()\n","\n","    criterion = torch.nn.MSELoss(size_average = True) \n","\n","    params_dict = dict(model.named_parameters())\n","    params = []\n","    base_lr = 0.001\n","\n","    for key, value in params_dict.items():\n","        if value.requires_grad:\n","          print(key)\n","          if 'weight' in key:\n","              params += [{'params':value, 'weight_decay':4e-3}]\n","          else:\n","              params += [{'params':value, 'weight_decay':0.0}]\n","\n","    optimizer = torch.optim.RMSprop(params, lr=base_lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.9, centered=False)\n","\n","    epochs = 100\n","    min_eval = sys.maxsize\n","    current_score = 0\n","\n","    for epoch in range(0,epochs):\n","        loss_sum = 0\n","        \n","        model.train()\n","        for i_batch, sample_batched in enumerate(train_dataset_loader):\n","            image = sample_batched[0].cuda().float()\n","            image = image.permute(0,3,2,1)/255\n","            y_pred = model(image, None, None).squeeze()\n","            y = sample_batched[1].cuda().float()\n","\n","            loss = criterion(y_pred, y) \n","            loss.backward() \n","            loss_sum += loss.item()\n","            optimizer.step() \n","            optimizer.zero_grad() \n","\n","        model.eval()\n","        print('Train Accuracy epoch {}, loss {} %'.format(epoch, loss_sum))\n","\n","        with torch.no_grad():\n","\n","            if epoch % 10 == 0:\n","                model.eval()\n","                eval_loss_sum = 0 \n","                result_pred = []\n","                result_act = []\n","                with torch.no_grad():\n","                    y2 = None\n","                    y_pred2 = None\n","                    for i_batch2, sample_batched2 in enumerate(test_dataset_loader):\n","\n","                        image2 = sample_batched2[0].cuda().float()\n","                        image2 = image2.permute(0,3,2,1)/255\n","                        y_pred2 = model(image2,None,None).squeeze()\n","                        y2 = sample_batched2[1].cuda().float()\n","                        eval_loss_sum += criterion(y_pred2, y2) \n","                        result_pred += y_pred2.tolist()\n","                        result_act += y2.tolist()\n","                    \n","                    print('')\n","                    print(' Test Accuracy  {} %'.format( eval_loss_sum))\n","\n","\n","                    if eval_loss_sum < min_eval:\n","                        current_score = mean_absolute_error(result_pred, result_act)\n","                        print(\"Score!\" ,current_score )\n","                        min_eval = eval_loss_sum\n","                        print(\"saved!\" ,current_score )\n","                        torch.save({'iter': epoch,\n","                          'model_state_dict': model.state_dict(),\n","                          'optimizer_state_dict': optimizer.state_dict(),\n","                          'best_ac': min_eval,\n","                          },\n","                          os.path.join('/content/drive/My Drive/Colab/Mosquito_Berkeley/Approach2/best_approach' + str(fold_count) + '.ckpt'))\n","\n","\n","    return current_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXZgxqyXHKPM","colab_type":"code","outputId":"e6a50bb5-bedb-46c5-c189-3191a65c0d1a","executionInfo":{"status":"ok","timestamp":1586442878519,"user_tz":420,"elapsed":45044217,"user":{"displayName":"Mario Alberto Durán Vega","photoUrl":"","userId":"12699467005499669145"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["scores = []\n","cv = KFold(n_splits=5, random_state=42, shuffle=True)\n","fold_count = 0\n","for train_index, test_index in cv.split(sentinel_frame, None):\n","    print('Fold')\n","    train, test  = sentinel_frame.iloc[train_index], sentinel_frame.iloc[test_index]\n","\n","    sentinel_dataset_train = SentinelDataset(data=train, root_dir='satellite/')\n","    sentinel_dataset_test = SentinelDataset(data=test, root_dir='satellite/')\n","\n","    train_dataset_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset_train,\n","                                                    batch_size=20,\n","                                                    shuffle=False)\n","    \n","    test_dataset_loader = torch.utils.data.DataLoader(dataset=sentinel_dataset_test,\n","                                                    batch_size=20,\n","                                                    shuffle=False)\n","    \n","\n","    current_score = train_darknet_net(sentinel_dataset_train,sentinel_dataset_test)\n","    scores.append(current_score)\n","    fold_count += 1\n","print(scores)\n","print( sum(scores) / len(scores) )\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 96039.78586578369 %\n","\n"," Test Accuracy  15520.3388671875 %\n","Score! 12.944622122091644\n","saved! 12.944622122091644\n","Train Accuracy epoch 1, loss 93791.61571598053 %\n","Train Accuracy epoch 2, loss 92746.08248806 %\n","Train Accuracy epoch 3, loss 91366.61149215698 %\n","Train Accuracy epoch 4, loss 90732.4849948883 %\n","Train Accuracy epoch 5, loss 89873.07434463501 %\n","Train Accuracy epoch 6, loss 88388.02087306976 %\n","Train Accuracy epoch 7, loss 88130.46438789368 %\n","Train Accuracy epoch 8, loss 88287.86022853851 %\n","Train Accuracy epoch 9, loss 87217.29424762726 %\n","Train Accuracy epoch 10, loss 86318.55828380585 %\n","\n"," Test Accuracy  13511.939453125 %\n","Score! 11.700261720647047\n","saved! 11.700261720647047\n","Train Accuracy epoch 11, loss 86564.89762115479 %\n","Train Accuracy epoch 12, loss 85709.68026924133 %\n","Train Accuracy epoch 13, loss 85546.04633140564 %\n","Train Accuracy epoch 14, loss 85411.07013320923 %\n","Train Accuracy epoch 15, loss 83959.13305854797 %\n","Train Accuracy epoch 16, loss 84466.28977394104 %\n","Train Accuracy epoch 17, loss 83363.98202705383 %\n","Train Accuracy epoch 18, loss 83878.18587112427 %\n","Train Accuracy epoch 19, loss 83576.35883331299 %\n","Train Accuracy epoch 20, loss 82805.90995025635 %\n","\n"," Test Accuracy  13341.55078125 %\n","Score! 12.111384573900773\n","saved! 12.111384573900773\n","Train Accuracy epoch 21, loss 83162.88067245483 %\n","Train Accuracy epoch 22, loss 82662.50205230713 %\n","Train Accuracy epoch 23, loss 82396.13454818726 %\n","Train Accuracy epoch 24, loss 82243.67715835571 %\n","Train Accuracy epoch 25, loss 81675.87224769592 %\n","Train Accuracy epoch 26, loss 81270.25945281982 %\n","Train Accuracy epoch 27, loss 81994.43587112427 %\n","Train Accuracy epoch 28, loss 81126.94883346558 %\n","Train Accuracy epoch 29, loss 80751.21543121338 %\n","Train Accuracy epoch 30, loss 81193.9868774414 %\n","\n"," Test Accuracy  12738.8134765625 %\n","Score! 11.044657339431621\n","saved! 11.044657339431621\n","Train Accuracy epoch 31, loss 79939.19856262207 %\n","Train Accuracy epoch 32, loss 80156.56840515137 %\n","Train Accuracy epoch 33, loss 79902.52821731567 %\n","Train Accuracy epoch 34, loss 80134.17714691162 %\n","Train Accuracy epoch 35, loss 79557.52787017822 %\n","Train Accuracy epoch 36, loss 79511.87463378906 %\n","Train Accuracy epoch 37, loss 79151.03272247314 %\n","Train Accuracy epoch 38, loss 79377.21437454224 %\n","Train Accuracy epoch 39, loss 79878.36827850342 %\n","Train Accuracy epoch 40, loss 79601.01489639282 %\n","\n"," Test Accuracy  12839.46484375 %\n","Train Accuracy epoch 41, loss 79153.141330719 %\n","Train Accuracy epoch 42, loss 78677.41249465942 %\n","Train Accuracy epoch 43, loss 79669.96042633057 %\n","Train Accuracy epoch 44, loss 79060.49887084961 %\n","Train Accuracy epoch 45, loss 78656.33236312866 %\n","Train Accuracy epoch 46, loss 78815.25273895264 %\n","Train Accuracy epoch 47, loss 78913.66975402832 %\n","Train Accuracy epoch 48, loss 78857.53969192505 %\n","Train Accuracy epoch 49, loss 78446.64056777954 %\n","Train Accuracy epoch 50, loss 78764.37473297119 %\n","\n"," Test Accuracy  12521.96484375 %\n","Score! 13.65794258588626\n","saved! 13.65794258588626\n","Train Accuracy epoch 51, loss 78663.45149612427 %\n","Train Accuracy epoch 52, loss 79636.99337005615 %\n","Train Accuracy epoch 53, loss 77640.22666549683 %\n","Train Accuracy epoch 54, loss 78167.64569473267 %\n","Train Accuracy epoch 55, loss 79069.56575775146 %\n","Train Accuracy epoch 56, loss 77308.97931289673 %\n","Train Accuracy epoch 57, loss 79648.44117736816 %\n","Train Accuracy epoch 58, loss 78601.9246749878 %\n","Train Accuracy epoch 59, loss 79492.36418151855 %\n","Train Accuracy epoch 60, loss 78298.25370788574 %\n","\n"," Test Accuracy  12217.986328125 %\n","Score! 12.440896688861612\n","saved! 12.440896688861612\n","Train Accuracy epoch 61, loss 78955.71826553345 %\n","Train Accuracy epoch 62, loss 78493.10795211792 %\n","Train Accuracy epoch 63, loss 79310.25161361694 %\n","Train Accuracy epoch 64, loss 78158.11124038696 %\n","Train Accuracy epoch 65, loss 78584.49610519409 %\n","Train Accuracy epoch 66, loss 78179.10544967651 %\n","Train Accuracy epoch 67, loss 78174.00172424316 %\n","Train Accuracy epoch 68, loss 79484.4415512085 %\n","Train Accuracy epoch 69, loss 78915.20748138428 %\n","Train Accuracy epoch 70, loss 78243.0502319336 %\n","\n"," Test Accuracy  12259.6328125 %\n","Train Accuracy epoch 71, loss 78112.17228317261 %\n","Train Accuracy epoch 72, loss 79098.97682189941 %\n","Train Accuracy epoch 73, loss 78456.40090179443 %\n","Train Accuracy epoch 74, loss 78954.40480804443 %\n","Train Accuracy epoch 75, loss 78991.77384185791 %\n","Train Accuracy epoch 76, loss 79371.53548431396 %\n","Train Accuracy epoch 77, loss 77873.33320999146 %\n","Train Accuracy epoch 78, loss 79160.60711669922 %\n","Train Accuracy epoch 79, loss 79102.04856109619 %\n","Train Accuracy epoch 80, loss 78934.69666290283 %\n","\n"," Test Accuracy  19696.4609375 %\n","Train Accuracy epoch 81, loss 78143.51291656494 %\n","Train Accuracy epoch 82, loss 77532.02410507202 %\n","Train Accuracy epoch 83, loss 78511.90692901611 %\n","Train Accuracy epoch 84, loss 77867.3592338562 %\n","Train Accuracy epoch 85, loss 80216.18549728394 %\n","Train Accuracy epoch 86, loss 78661.39196014404 %\n","Train Accuracy epoch 87, loss 77142.00232696533 %\n","Train Accuracy epoch 88, loss 78443.2486114502 %\n","Train Accuracy epoch 89, loss 77621.80805969238 %\n","Train Accuracy epoch 90, loss 77613.6886177063 %\n","\n"," Test Accuracy  13263.8203125 %\n","Train Accuracy epoch 91, loss 77398.6904373169 %\n","Train Accuracy epoch 92, loss 77673.32595062256 %\n","Train Accuracy epoch 93, loss 77689.13976669312 %\n","Train Accuracy epoch 94, loss 77704.85954284668 %\n","Train Accuracy epoch 95, loss 79207.885887146 %\n","Train Accuracy epoch 96, loss 78217.92865753174 %\n","Train Accuracy epoch 97, loss 78629.39591598511 %\n","Train Accuracy epoch 98, loss 77639.48215484619 %\n","Train Accuracy epoch 99, loss 78378.90897369385 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 88009.30087280273 %\n","\n"," Test Accuracy  23080.470703125 %\n","Score! 14.496053413292508\n","saved! 14.496053413292508\n","Train Accuracy epoch 1, loss 86284.99170398712 %\n","Train Accuracy epoch 2, loss 85035.01092910767 %\n","Train Accuracy epoch 3, loss 83678.39536476135 %\n","Train Accuracy epoch 4, loss 82497.32294845581 %\n","Train Accuracy epoch 5, loss 82916.06280517578 %\n","Train Accuracy epoch 6, loss 81806.07965660095 %\n","Train Accuracy epoch 7, loss 81158.93196678162 %\n","Train Accuracy epoch 8, loss 80042.79108810425 %\n","Train Accuracy epoch 9, loss 79517.92651557922 %\n","Train Accuracy epoch 10, loss 79393.70984649658 %\n","\n"," Test Accuracy  20413.5546875 %\n","Score! 13.516205692475225\n","saved! 13.516205692475225\n","Train Accuracy epoch 11, loss 79028.77882385254 %\n","Train Accuracy epoch 12, loss 78512.15789985657 %\n","Train Accuracy epoch 13, loss 78143.69359207153 %\n","Train Accuracy epoch 14, loss 77250.36339378357 %\n","Train Accuracy epoch 15, loss 77329.76443862915 %\n","Train Accuracy epoch 16, loss 77092.08064651489 %\n","Train Accuracy epoch 17, loss 76593.25267410278 %\n","Train Accuracy epoch 18, loss 77943.83185005188 %\n","Train Accuracy epoch 19, loss 77067.65822601318 %\n","Train Accuracy epoch 20, loss 76381.24284362793 %\n","\n"," Test Accuracy  20346.681640625 %\n","Score! 14.043524293399152\n","saved! 14.043524293399152\n","Train Accuracy epoch 21, loss 76665.03252792358 %\n","Train Accuracy epoch 22, loss 75758.6245880127 %\n","Train Accuracy epoch 23, loss 76810.66100692749 %\n","Train Accuracy epoch 24, loss 75885.74509429932 %\n","Train Accuracy epoch 25, loss 75515.96070861816 %\n","Train Accuracy epoch 26, loss 76192.43072128296 %\n","Train Accuracy epoch 27, loss 75664.91146469116 %\n","Train Accuracy epoch 28, loss 75657.42449569702 %\n","Train Accuracy epoch 29, loss 75295.063331604 %\n","Train Accuracy epoch 30, loss 75245.29425430298 %\n","\n"," Test Accuracy  22002.630859375 %\n","Train Accuracy epoch 31, loss 75323.95140457153 %\n","Train Accuracy epoch 32, loss 75337.61916351318 %\n","Train Accuracy epoch 33, loss 74606.31829452515 %\n","Train Accuracy epoch 34, loss 75188.79927444458 %\n","Train Accuracy epoch 35, loss 74922.43528747559 %\n","Train Accuracy epoch 36, loss 74356.856174469 %\n","Train Accuracy epoch 37, loss 73976.85177993774 %\n","Train Accuracy epoch 38, loss 73099.53345108032 %\n","Train Accuracy epoch 39, loss 73419.07593917847 %\n","Train Accuracy epoch 40, loss 72963.04203033447 %\n","\n"," Test Accuracy  20148.537109375 %\n","Score! 12.950430141849282\n","saved! 12.950430141849282\n","Train Accuracy epoch 41, loss 73144.06097793579 %\n","Train Accuracy epoch 42, loss 73549.10545349121 %\n","Train Accuracy epoch 43, loss 72794.93453979492 %\n","Train Accuracy epoch 44, loss 73097.8904838562 %\n","Train Accuracy epoch 45, loss 72322.77798843384 %\n","Train Accuracy epoch 46, loss 72193.55340576172 %\n","Train Accuracy epoch 47, loss 72271.51276397705 %\n","Train Accuracy epoch 48, loss 72827.01539230347 %\n","Train Accuracy epoch 49, loss 72699.4635925293 %\n","Train Accuracy epoch 50, loss 72256.4317855835 %\n","\n"," Test Accuracy  18340.16015625 %\n","Score! 15.360899002169385\n","saved! 15.360899002169385\n","Train Accuracy epoch 51, loss 72988.4913444519 %\n","Train Accuracy epoch 52, loss 73177.11169433594 %\n","Train Accuracy epoch 53, loss 71523.54586029053 %\n","Train Accuracy epoch 54, loss 73004.77098464966 %\n","Train Accuracy epoch 55, loss 71764.1983718872 %\n","Train Accuracy epoch 56, loss 72831.80741500854 %\n","Train Accuracy epoch 57, loss 71563.44687652588 %\n","Train Accuracy epoch 58, loss 72693.90393447876 %\n","Train Accuracy epoch 59, loss 72047.04689025879 %\n","Train Accuracy epoch 60, loss 72648.39601898193 %\n","\n"," Test Accuracy  18812.451171875 %\n","Train Accuracy epoch 61, loss 71916.65937042236 %\n","Train Accuracy epoch 62, loss 71655.87364578247 %\n","Train Accuracy epoch 63, loss 71863.5365524292 %\n","Train Accuracy epoch 64, loss 72121.55854034424 %\n","Train Accuracy epoch 65, loss 71238.75793838501 %\n","Train Accuracy epoch 66, loss 71891.92366027832 %\n","Train Accuracy epoch 67, loss 71769.10586547852 %\n","Train Accuracy epoch 68, loss 71694.59457397461 %\n","Train Accuracy epoch 69, loss 73031.92116546631 %\n","Train Accuracy epoch 70, loss 72633.63918304443 %\n","\n"," Test Accuracy  19655.0859375 %\n","Train Accuracy epoch 71, loss 72061.04086303711 %\n","Train Accuracy epoch 72, loss 72879.17995452881 %\n","Train Accuracy epoch 73, loss 72077.6572303772 %\n","Train Accuracy epoch 74, loss 71789.90977478027 %\n","Train Accuracy epoch 75, loss 72332.78228378296 %\n","Train Accuracy epoch 76, loss 72329.60721588135 %\n","Train Accuracy epoch 77, loss 72233.35368728638 %\n","Train Accuracy epoch 78, loss 72925.54382324219 %\n","Train Accuracy epoch 79, loss 71758.14253234863 %\n","Train Accuracy epoch 80, loss 72125.88972473145 %\n","\n"," Test Accuracy  20302.8984375 %\n","Train Accuracy epoch 81, loss 72520.86326980591 %\n","Train Accuracy epoch 82, loss 71776.33811950684 %\n","Train Accuracy epoch 83, loss 71597.00747680664 %\n","Train Accuracy epoch 84, loss 72275.5528755188 %\n","Train Accuracy epoch 85, loss 72624.73765563965 %\n","Train Accuracy epoch 86, loss 72925.59934234619 %\n","Train Accuracy epoch 87, loss 71983.11420440674 %\n","Train Accuracy epoch 88, loss 72371.54536056519 %\n","Train Accuracy epoch 89, loss 73086.19223022461 %\n","Train Accuracy epoch 90, loss 72465.41387939453 %\n","\n"," Test Accuracy  19874.705078125 %\n","Train Accuracy epoch 91, loss 72754.4806098938 %\n","Train Accuracy epoch 92, loss 72683.52653503418 %\n","Train Accuracy epoch 93, loss 72750.31734085083 %\n","Train Accuracy epoch 94, loss 71023.5290222168 %\n","Train Accuracy epoch 95, loss 72598.96406555176 %\n","Train Accuracy epoch 96, loss 72142.2308959961 %\n","Train Accuracy epoch 97, loss 71543.26181030273 %\n","Train Accuracy epoch 98, loss 72006.30682754517 %\n","Train Accuracy epoch 99, loss 72916.89161682129 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 91381.3415260315 %\n","\n"," Test Accuracy  20133.04296875 %\n","Score! 12.533837504696423\n","saved! 12.533837504696423\n","Train Accuracy epoch 1, loss 89617.3055934906 %\n","Train Accuracy epoch 2, loss 87901.91896247864 %\n","Train Accuracy epoch 3, loss 87172.88298225403 %\n","Train Accuracy epoch 4, loss 87030.78859138489 %\n","Train Accuracy epoch 5, loss 84784.20680999756 %\n","Train Accuracy epoch 6, loss 85153.33562088013 %\n","Train Accuracy epoch 7, loss 83494.57718467712 %\n","Train Accuracy epoch 8, loss 82503.27345466614 %\n","Train Accuracy epoch 9, loss 81733.48722553253 %\n","Train Accuracy epoch 10, loss 81917.75102424622 %\n","\n"," Test Accuracy  17807.939453125 %\n","Score! 10.854562085498998\n","saved! 10.854562085498998\n","Train Accuracy epoch 11, loss 80864.89093399048 %\n","Train Accuracy epoch 12, loss 80823.65807723999 %\n","Train Accuracy epoch 13, loss 80565.24898338318 %\n","Train Accuracy epoch 14, loss 80076.45478439331 %\n","Train Accuracy epoch 15, loss 80574.0516166687 %\n","Train Accuracy epoch 16, loss 79289.44529533386 %\n","Train Accuracy epoch 17, loss 79514.77876663208 %\n","Train Accuracy epoch 18, loss 79332.09781455994 %\n","Train Accuracy epoch 19, loss 78571.74839782715 %\n","Train Accuracy epoch 20, loss 78809.2194480896 %\n","\n"," Test Accuracy  17686.66015625 %\n","Score! 12.072805615486923\n","saved! 12.072805615486923\n","Train Accuracy epoch 21, loss 79348.9963092804 %\n","Train Accuracy epoch 22, loss 79138.91052818298 %\n","Train Accuracy epoch 23, loss 78924.11870384216 %\n","Train Accuracy epoch 24, loss 77671.63248634338 %\n","Train Accuracy epoch 25, loss 78841.7361946106 %\n","Train Accuracy epoch 26, loss 78892.34118270874 %\n","Train Accuracy epoch 27, loss 77847.02458953857 %\n","Train Accuracy epoch 28, loss 78155.81052017212 %\n","Train Accuracy epoch 29, loss 77284.91913604736 %\n","Train Accuracy epoch 30, loss 77354.99564361572 %\n","\n"," Test Accuracy  17313.47265625 %\n","Score! 11.840513749963339\n","saved! 11.840513749963339\n","Train Accuracy epoch 31, loss 77386.6934928894 %\n","Train Accuracy epoch 32, loss 77877.15766143799 %\n","Train Accuracy epoch 33, loss 78016.94390106201 %\n","Train Accuracy epoch 34, loss 77425.82285690308 %\n","Train Accuracy epoch 35, loss 77892.79578781128 %\n","Train Accuracy epoch 36, loss 77732.9160118103 %\n","Train Accuracy epoch 37, loss 77050.98990631104 %\n","Train Accuracy epoch 38, loss 77287.75609588623 %\n","Train Accuracy epoch 39, loss 77457.72459411621 %\n","Train Accuracy epoch 40, loss 76701.86332702637 %\n","\n"," Test Accuracy  17139.88671875 %\n","Score! 14.094053335469447\n","saved! 14.094053335469447\n","Train Accuracy epoch 41, loss 77413.68845748901 %\n","Train Accuracy epoch 42, loss 77515.26962280273 %\n","Train Accuracy epoch 43, loss 77403.47644805908 %\n","Train Accuracy epoch 44, loss 77306.85918426514 %\n","Train Accuracy epoch 45, loss 77031.12036514282 %\n","Train Accuracy epoch 46, loss 76841.28274917603 %\n","Train Accuracy epoch 47, loss 76875.46223449707 %\n","Train Accuracy epoch 48, loss 77043.65602874756 %\n","Train Accuracy epoch 49, loss 77189.52568054199 %\n","Train Accuracy epoch 50, loss 76958.60730361938 %\n","\n"," Test Accuracy  16993.248046875 %\n","Score! 14.117445034745298\n","saved! 14.117445034745298\n","Train Accuracy epoch 51, loss 76639.0336151123 %\n","Train Accuracy epoch 52, loss 75597.60242462158 %\n","Train Accuracy epoch 53, loss 76148.05407714844 %\n","Train Accuracy epoch 54, loss 75727.57846069336 %\n","Train Accuracy epoch 55, loss 74953.4118385315 %\n","Train Accuracy epoch 56, loss 74969.25392150879 %\n","Train Accuracy epoch 57, loss 75771.3557395935 %\n","Train Accuracy epoch 58, loss 75457.21354675293 %\n","Train Accuracy epoch 59, loss 74356.25157928467 %\n","Train Accuracy epoch 60, loss 74676.1336479187 %\n","\n"," Test Accuracy  17731.5390625 %\n","Train Accuracy epoch 61, loss 74563.6337890625 %\n","Train Accuracy epoch 62, loss 74468.21662521362 %\n","Train Accuracy epoch 63, loss 74295.95447540283 %\n","Train Accuracy epoch 64, loss 73816.28940963745 %\n","Train Accuracy epoch 65, loss 74185.60667419434 %\n","Train Accuracy epoch 66, loss 75466.30110168457 %\n","Train Accuracy epoch 67, loss 75052.65034484863 %\n","Train Accuracy epoch 68, loss 73237.52125167847 %\n","Train Accuracy epoch 69, loss 75232.12511062622 %\n","Train Accuracy epoch 70, loss 74214.93663787842 %\n","\n"," Test Accuracy  18059.015625 %\n","Train Accuracy epoch 71, loss 74626.1986579895 %\n","Train Accuracy epoch 72, loss 73128.45935821533 %\n","Train Accuracy epoch 73, loss 73511.99805831909 %\n","Train Accuracy epoch 74, loss 74085.07579803467 %\n","Train Accuracy epoch 75, loss 73142.91946411133 %\n","Train Accuracy epoch 76, loss 73773.08586883545 %\n","Train Accuracy epoch 77, loss 73362.30530929565 %\n","Train Accuracy epoch 78, loss 72916.47452545166 %\n","Train Accuracy epoch 79, loss 73622.16527557373 %\n","Train Accuracy epoch 80, loss 73884.68027114868 %\n","\n"," Test Accuracy  16487.888671875 %\n","Score! 12.304059676182122\n","saved! 12.304059676182122\n","Train Accuracy epoch 81, loss 73204.663230896 %\n","Train Accuracy epoch 82, loss 73646.1802444458 %\n","Train Accuracy epoch 83, loss 74164.15779876709 %\n","Train Accuracy epoch 84, loss 73979.80749511719 %\n","Train Accuracy epoch 85, loss 73639.02223205566 %\n","Train Accuracy epoch 86, loss 74061.7809677124 %\n","Train Accuracy epoch 87, loss 73950.05207061768 %\n","Train Accuracy epoch 88, loss 72884.81683731079 %\n","Train Accuracy epoch 89, loss 74539.79211425781 %\n","Train Accuracy epoch 90, loss 74036.25121307373 %\n","\n"," Test Accuracy  17984.32421875 %\n","Train Accuracy epoch 91, loss 73865.03759002686 %\n","Train Accuracy epoch 92, loss 74311.7554359436 %\n","Train Accuracy epoch 93, loss 74582.99904251099 %\n","Train Accuracy epoch 94, loss 73584.83818435669 %\n","Train Accuracy epoch 95, loss 73752.61237716675 %\n","Train Accuracy epoch 96, loss 74189.72351074219 %\n","Train Accuracy epoch 97, loss 74385.65588378906 %\n","Train Accuracy epoch 98, loss 73093.19609069824 %\n","Train Accuracy epoch 99, loss 74197.22728729248 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 71887.04796218872 %\n","\n"," Test Accuracy  39776.8203125 %\n","Score! 13.260631238906829\n","saved! 13.260631238906829\n","Train Accuracy epoch 1, loss 70308.46635627747 %\n","Train Accuracy epoch 2, loss 68633.20254898071 %\n","Train Accuracy epoch 3, loss 67301.97316169739 %\n","Train Accuracy epoch 4, loss 66497.79860019684 %\n","Train Accuracy epoch 5, loss 65552.62239074707 %\n","Train Accuracy epoch 6, loss 64819.076389312744 %\n","Train Accuracy epoch 7, loss 63623.23511505127 %\n","Train Accuracy epoch 8, loss 63307.466875076294 %\n","Train Accuracy epoch 9, loss 62133.093309402466 %\n","Train Accuracy epoch 10, loss 62219.15185165405 %\n","\n"," Test Accuracy  38111.32421875 %\n","Score! 12.319019490871394\n","saved! 12.319019490871394\n","Train Accuracy epoch 11, loss 61837.402135849 %\n","Train Accuracy epoch 12, loss 60834.056230545044 %\n","Train Accuracy epoch 13, loss 60432.36982727051 %\n","Train Accuracy epoch 14, loss 60636.1667842865 %\n","Train Accuracy epoch 15, loss 59426.55298423767 %\n","Train Accuracy epoch 16, loss 60323.92712020874 %\n","Train Accuracy epoch 17, loss 59618.99151611328 %\n","Train Accuracy epoch 18, loss 60002.90651702881 %\n","Train Accuracy epoch 19, loss 59473.504890441895 %\n","Train Accuracy epoch 20, loss 59535.38883972168 %\n","\n"," Test Accuracy  36746.51171875 %\n","Score! 11.916121816281045\n","saved! 11.916121816281045\n","Train Accuracy epoch 21, loss 58620.941356658936 %\n","Train Accuracy epoch 22, loss 58790.1449508667 %\n","Train Accuracy epoch 23, loss 59007.22227478027 %\n","Train Accuracy epoch 24, loss 58206.588565826416 %\n","Train Accuracy epoch 25, loss 58990.33248901367 %\n","Train Accuracy epoch 26, loss 58100.18231201172 %\n","Train Accuracy epoch 27, loss 58363.88750076294 %\n","Train Accuracy epoch 28, loss 57881.14820480347 %\n","Train Accuracy epoch 29, loss 57991.94668197632 %\n","Train Accuracy epoch 30, loss 57335.88285827637 %\n","\n"," Test Accuracy  36828.375 %\n","Train Accuracy epoch 31, loss 57108.428173065186 %\n","Train Accuracy epoch 32, loss 57371.57390975952 %\n","Train Accuracy epoch 33, loss 57565.97850036621 %\n","Train Accuracy epoch 34, loss 56396.597690582275 %\n","Train Accuracy epoch 35, loss 56214.87105178833 %\n","Train Accuracy epoch 36, loss 56093.65916824341 %\n","Train Accuracy epoch 37, loss 56066.31042480469 %\n","Train Accuracy epoch 38, loss 55451.243492126465 %\n","Train Accuracy epoch 39, loss 55702.4462928772 %\n","Train Accuracy epoch 40, loss 55446.97792816162 %\n","\n"," Test Accuracy  35832.734375 %\n","Score! 12.788558089497066\n","saved! 12.788558089497066\n","Train Accuracy epoch 41, loss 55547.66037750244 %\n","Train Accuracy epoch 42, loss 55501.30662918091 %\n","Train Accuracy epoch 43, loss 55170.60854721069 %\n","Train Accuracy epoch 44, loss 55180.49546432495 %\n","Train Accuracy epoch 45, loss 55437.759075164795 %\n","Train Accuracy epoch 46, loss 54999.29745101929 %\n","Train Accuracy epoch 47, loss 55273.35636520386 %\n","Train Accuracy epoch 48, loss 55209.05680465698 %\n","Train Accuracy epoch 49, loss 54735.38215637207 %\n","Train Accuracy epoch 50, loss 55268.40326690674 %\n","\n"," Test Accuracy  35702.921875 %\n","Score! 13.757844724277458\n","saved! 13.757844724277458\n","Train Accuracy epoch 51, loss 54482.0821723938 %\n","Train Accuracy epoch 52, loss 54757.82364273071 %\n","Train Accuracy epoch 53, loss 54806.89087677002 %\n","Train Accuracy epoch 54, loss 54746.43175506592 %\n","Train Accuracy epoch 55, loss 55065.32036972046 %\n","Train Accuracy epoch 56, loss 55227.645248413086 %\n","Train Accuracy epoch 57, loss 55282.0930480957 %\n","Train Accuracy epoch 58, loss 55027.389781951904 %\n","Train Accuracy epoch 59, loss 55409.7993888855 %\n","Train Accuracy epoch 60, loss 54883.80904006958 %\n","\n"," Test Accuracy  36999.1640625 %\n","Train Accuracy epoch 61, loss 54832.6070022583 %\n","Train Accuracy epoch 62, loss 54498.437728881836 %\n","Train Accuracy epoch 63, loss 54617.79177856445 %\n","Train Accuracy epoch 64, loss 54626.64249038696 %\n","Train Accuracy epoch 65, loss 55164.30489349365 %\n","Train Accuracy epoch 66, loss 54841.689765930176 %\n","Train Accuracy epoch 67, loss 54795.98776626587 %\n","Train Accuracy epoch 68, loss 54886.31131744385 %\n","Train Accuracy epoch 69, loss 55300.24426269531 %\n","Train Accuracy epoch 70, loss 54772.416175842285 %\n","\n"," Test Accuracy  35897.90625 %\n","Train Accuracy epoch 71, loss 54958.892517089844 %\n","Train Accuracy epoch 72, loss 54964.274253845215 %\n","Train Accuracy epoch 73, loss 55186.9642829895 %\n","Train Accuracy epoch 74, loss 54881.32524108887 %\n","Train Accuracy epoch 75, loss 54204.56658554077 %\n","Train Accuracy epoch 76, loss 55635.92850494385 %\n","Train Accuracy epoch 77, loss 54652.28647994995 %\n","Train Accuracy epoch 78, loss 55411.913429260254 %\n","Train Accuracy epoch 79, loss 55171.34140396118 %\n","Train Accuracy epoch 80, loss 54520.033489227295 %\n","\n"," Test Accuracy  35286.9140625 %\n","Score! 13.658049833656538\n","saved! 13.658049833656538\n","Train Accuracy epoch 81, loss 55354.95804595947 %\n","Train Accuracy epoch 82, loss 54766.567459106445 %\n","Train Accuracy epoch 83, loss 54798.92278671265 %\n","Train Accuracy epoch 84, loss 55566.088306427 %\n","Train Accuracy epoch 85, loss 54296.70027923584 %\n","Train Accuracy epoch 86, loss 54856.53755950928 %\n","Train Accuracy epoch 87, loss 54736.64037322998 %\n","Train Accuracy epoch 88, loss 54950.35754394531 %\n","Train Accuracy epoch 89, loss 54977.61042404175 %\n","Train Accuracy epoch 90, loss 55061.22840881348 %\n","\n"," Test Accuracy  39067.546875 %\n","Train Accuracy epoch 91, loss 54880.385902404785 %\n","Train Accuracy epoch 92, loss 54945.69843673706 %\n","Train Accuracy epoch 93, loss 54560.18733215332 %\n","Train Accuracy epoch 94, loss 55115.41576004028 %\n","Train Accuracy epoch 95, loss 54932.773250579834 %\n","Train Accuracy epoch 96, loss 54425.91563415527 %\n","Train Accuracy epoch 97, loss 54751.98857116699 %\n","Train Accuracy epoch 98, loss 54064.47549819946 %\n","Train Accuracy epoch 99, loss 54661.57508850098 %\n","Fold\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["module_list.12.linear.weight\n","module_list.12.linear.bias\n","module_list.12.batch_norm.weight\n","module_list.12.batch_norm.bias\n","module_list.13.linear.weight\n","module_list.13.linear.bias\n","module_list.13.batch_norm.weight\n","module_list.13.batch_norm.bias\n","module_list.14.linear.weight\n","module_list.14.linear.bias\n","module_list.14.batch_norm.weight\n","module_list.14.batch_norm.bias\n","Train Accuracy epoch 0, loss 99775.01598358154 %\n","\n"," Test Accuracy  11654.37109375 %\n","Score! 11.913454268434567\n","saved! 11.913454268434567\n","Train Accuracy epoch 1, loss 97668.88698577881 %\n","Train Accuracy epoch 2, loss 96308.84237003326 %\n","Train Accuracy epoch 3, loss 94758.21427345276 %\n","Train Accuracy epoch 4, loss 94223.57270002365 %\n","Train Accuracy epoch 5, loss 93469.47418880463 %\n","Train Accuracy epoch 6, loss 92434.33746814728 %\n","Train Accuracy epoch 7, loss 92457.52846431732 %\n","Train Accuracy epoch 8, loss 91045.13549613953 %\n","Train Accuracy epoch 9, loss 91230.58498287201 %\n","Train Accuracy epoch 10, loss 90060.03569316864 %\n","\n"," Test Accuracy  9634.9921875 %\n","Score! 10.826466398368968\n","saved! 10.826466398368968\n","Train Accuracy epoch 11, loss 89412.8191871643 %\n","Train Accuracy epoch 12, loss 88732.23091506958 %\n","Train Accuracy epoch 13, loss 89134.16484260559 %\n","Train Accuracy epoch 14, loss 88960.6914844513 %\n","Train Accuracy epoch 15, loss 88771.66016578674 %\n","Train Accuracy epoch 16, loss 87795.04488182068 %\n","Train Accuracy epoch 17, loss 87795.00604248047 %\n","Train Accuracy epoch 18, loss 86885.82655906677 %\n","Train Accuracy epoch 19, loss 87602.37091636658 %\n","Train Accuracy epoch 20, loss 87356.327709198 %\n","\n"," Test Accuracy  9197.5283203125 %\n","Score! 11.110090681231847\n","saved! 11.110090681231847\n","Train Accuracy epoch 21, loss 86819.63990783691 %\n","Train Accuracy epoch 22, loss 85568.54335021973 %\n","Train Accuracy epoch 23, loss 86615.33671569824 %\n","Train Accuracy epoch 24, loss 86097.45714950562 %\n","Train Accuracy epoch 25, loss 86512.5861377716 %\n","Train Accuracy epoch 26, loss 87086.45562362671 %\n","Train Accuracy epoch 27, loss 86209.92021560669 %\n","Train Accuracy epoch 28, loss 85643.26444625854 %\n","Train Accuracy epoch 29, loss 85242.07176208496 %\n","Train Accuracy epoch 30, loss 86383.37544250488 %\n","\n"," Test Accuracy  9286.0498046875 %\n","Train Accuracy epoch 31, loss 85895.66171264648 %\n","Train Accuracy epoch 32, loss 85971.08951187134 %\n","Train Accuracy epoch 33, loss 84725.72647476196 %\n","Train Accuracy epoch 34, loss 84609.1622390747 %\n","Train Accuracy epoch 35, loss 83863.01503372192 %\n","Train Accuracy epoch 36, loss 84146.47960281372 %\n","Train Accuracy epoch 37, loss 84599.53816604614 %\n","Train Accuracy epoch 38, loss 84088.11535263062 %\n","Train Accuracy epoch 39, loss 84045.3616027832 %\n","Train Accuracy epoch 40, loss 83093.79146957397 %\n","\n"," Test Accuracy  9028.373046875 %\n","Score! 13.449320778988376\n","saved! 13.449320778988376\n","Train Accuracy epoch 41, loss 83751.9303894043 %\n","Train Accuracy epoch 42, loss 82481.89100646973 %\n","Train Accuracy epoch 43, loss 82744.72383880615 %\n","Train Accuracy epoch 44, loss 82703.88006591797 %\n","Train Accuracy epoch 45, loss 82747.5184173584 %\n","Train Accuracy epoch 46, loss 83745.1798324585 %\n","Train Accuracy epoch 47, loss 82514.46357345581 %\n","Train Accuracy epoch 48, loss 81781.53622055054 %\n","Train Accuracy epoch 49, loss 81836.48941421509 %\n","Train Accuracy epoch 50, loss 82257.35816955566 %\n","\n"," Test Accuracy  9001.2783203125 %\n","Score! 12.384825560125973\n","saved! 12.384825560125973\n","Train Accuracy epoch 51, loss 82653.16864776611 %\n","Train Accuracy epoch 52, loss 81756.16798019409 %\n","Train Accuracy epoch 53, loss 82129.34432601929 %\n","Train Accuracy epoch 54, loss 81875.37491226196 %\n","Train Accuracy epoch 55, loss 81451.59526062012 %\n","Train Accuracy epoch 56, loss 82643.55889892578 %\n","Train Accuracy epoch 57, loss 81716.61120605469 %\n","Train Accuracy epoch 58, loss 82763.53824615479 %\n","Train Accuracy epoch 59, loss 82565.50127410889 %\n","Train Accuracy epoch 60, loss 82748.65096282959 %\n","\n"," Test Accuracy  8802.0087890625 %\n","Score! 11.81855344536281\n","saved! 11.81855344536281\n","Train Accuracy epoch 61, loss 82752.00400161743 %\n","Train Accuracy epoch 62, loss 81766.80303955078 %\n","Train Accuracy epoch 63, loss 81521.10857391357 %\n","Train Accuracy epoch 64, loss 81904.0731086731 %\n","Train Accuracy epoch 65, loss 82642.52834320068 %\n","Train Accuracy epoch 66, loss 81493.88121032715 %\n","Train Accuracy epoch 67, loss 82079.6515159607 %\n","Train Accuracy epoch 68, loss 81057.15784835815 %\n","Train Accuracy epoch 69, loss 81851.58001327515 %\n","Train Accuracy epoch 70, loss 81591.21174240112 %\n","\n"," Test Accuracy  9022.2783203125 %\n","Train Accuracy epoch 71, loss 80980.719455719 %\n","Train Accuracy epoch 72, loss 81615.4753074646 %\n","Train Accuracy epoch 73, loss 82828.18556213379 %\n","Train Accuracy epoch 74, loss 82712.0149307251 %\n","Train Accuracy epoch 75, loss 81416.29535675049 %\n","Train Accuracy epoch 76, loss 80900.5622253418 %\n","Train Accuracy epoch 77, loss 80310.74485015869 %\n","Train Accuracy epoch 78, loss 82533.1029548645 %\n","Train Accuracy epoch 79, loss 81623.86263656616 %\n","Train Accuracy epoch 80, loss 81858.0336151123 %\n","\n"," Test Accuracy  19371.35546875 %\n","Train Accuracy epoch 81, loss 82151.41030883789 %\n","Train Accuracy epoch 82, loss 82320.91854858398 %\n","Train Accuracy epoch 83, loss 82816.37301635742 %\n","Train Accuracy epoch 84, loss 81662.57855987549 %\n","Train Accuracy epoch 85, loss 82457.2991027832 %\n","Train Accuracy epoch 86, loss 81238.46859741211 %\n","Train Accuracy epoch 87, loss 80456.0866317749 %\n","Train Accuracy epoch 88, loss 81454.67965316772 %\n","Train Accuracy epoch 89, loss 81426.4909362793 %\n","Train Accuracy epoch 90, loss 81516.60023117065 %\n","\n"," Test Accuracy  10640.89453125 %\n","Train Accuracy epoch 91, loss 81571.391746521 %\n","Train Accuracy epoch 92, loss 82272.76692962646 %\n","Train Accuracy epoch 93, loss 81364.10262298584 %\n","Train Accuracy epoch 94, loss 82569.22206878662 %\n","Train Accuracy epoch 95, loss 82643.31658935547 %\n","Train Accuracy epoch 96, loss 81266.24099731445 %\n","Train Accuracy epoch 97, loss 82121.27863311768 %\n","Train Accuracy epoch 98, loss 81661.03848266602 %\n","Train Accuracy epoch 99, loss 81865.79886627197 %\n","[12.440896688861612, 15.360899002169385, 12.304059676182122, 13.658049833656538, 11.81855344536281]\n","13.116491729246494\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hi_51SSJ11Hq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}